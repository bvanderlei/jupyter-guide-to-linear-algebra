{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthogonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the most important applications of inner products involve finding and using sets of vectors that are mutually orthogonal.  A set of nonzero vectors $\\{U_1, U_2, U_3 ... U_n\\}$ is **mutually orthogonal** if $U_i\\cdot U_j = 0$ whenever $i \\neq j$.  If a set of vectors is mutually orthogonal *and* every vector in the set is a unit vector, we say the set is **orthnormal**.  In other words, every vector in an orthonormal set has magnitude one, and is orthogonal to every other vector in the set.  Orthonormal sets must be linearly independent, so it makes sense to think of them as a basis for some vector subspace.  Any collection of vectors from the standard bases of $\\mathbb{R}^n$ are orthonormal sets.  For example, the set of vectors $\\{E_1, E_4, E_5\\}$ from the standard basis of $\\mathbb{R}^5$ forms a orthonormal basis for a subspace of $\\mathbb{R}^5$.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "E_1 = \\left[ \\begin{array}{r} 1\\\\0\\\\0\\\\0\\\\0 \\end{array}\\right] \\hspace{0.7cm} \n",
    "E_4 = \\left[ \\begin{array}{r} 0\\\\0\\\\0\\\\1\\\\0 \\end{array}\\right] \\hspace{0.7cm}\n",
    "E_5 = \\left[ \\begin{array}{r} 0\\\\0\\\\0\\\\0\\\\1 \\end{array}\\right] \\hspace{0.7cm}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "In this section we will focus on a process called orthogonalization.  Given a set of linearly independent vectors  $\\{V_1, V_2, V_3 ... V_n\\}$, we wish to find an orthonormal set of vectors  $\\{U_1, U_2, U_3 ... U_n\\}$ such that the span of  $\\{U_1, U_2, U_3 ... U_n\\}$ is the same as the span of  $\\{V_1, V_2, V_3 ... V_n\\}$.  In other words, we want both sets to bases for the same subspace.\n",
    "\n",
    "One of the primary advantages of using orthonormal bases is that the calculation of [coordinate vectors](Bases.ipynb) is greatly simplified.  Recall that if we have a typical basis $\\beta = \\{V_1, V_2, V_3 ... V_n\\}$ for a subspace $\\mathcal{V}$, and a vector $X$ in $\\mathcal{V}$, the coordinates with respect to $\\beta$ are the values of $c_1$, $c_2$,...,$c_n$ such that\n",
    "$X = c_1V_1 + c_2V_2 + ... c_nV_n$.  This requires that we solve the linear system $A[X]_{\\beta}=X$, where $A$ is the matrix that has the basis vectors as its columns, and $[X]_\\beta$ is the coordinate vector.  If instead we have an orthonormal basis $\\alpha = \\{U_1, U_2, U_3 ... U_n\\}$, there is a convenient shortcut to solving $X = b_1U_1 + b_2U_2 + ... b_nU_n$.  Let's observe the result of taking the dot product of both sides of the equation with $U_k$.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "X\\cdot U_k & = & (b_1U_1 + b_2U_2 + ... b_nU_n)\\cdot U_k \\\\\n",
    " & = & b_1(U_1\\cdot U_k) + b_2(U_2\\cdot U_k) + ... b_n(U_n\\cdot U_k) \\\\\n",
    " & = & b_k \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "All of the products $U_i\\cdot U_k$ are zero except for $U_k\\cdot U_k$, which is 1.  This means that instead of solving a system to find the coordinates, we can compute each $b_k$ directly as $X\\cdot U_k$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projecting vectors onto vectors\n",
    "\n",
    "An important step in orthogonalization involves decomposing a vector $B$ into orthogonal components based on the direction of another vector $V$.  Specifically, we want to determine two vectors, $\\hat{B}$ and $E$, such that $\\hat{B}$ is in the same direction as $V$, $E$ is orthogonal to $V$, and $B = \\hat{B} + E$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "options = {\"head_width\":0.1, \"head_length\":0.2, \"length_includes_head\":True}\n",
    "\n",
    "ax.arrow(0,0,2,3,fc='b',ec='b',**options)\n",
    "ax.arrow(0,0,4,2,fc='b',ec='b',**options)\n",
    "ax.arrow(0,0,2.8,1.4,fc='b',ec='r',**options)\n",
    "ax.arrow(2.8,1.4,-0.8,1.6,fc='b',ec='r',**options)\n",
    "\n",
    "ax.text(1,2,'$B$')\n",
    "ax.text(3.2,1.2,'$V$')\n",
    "ax.text(2,0.6,'$\\hat{B}$')\n",
    "ax.text(2.5,2.5,'$E$')\n",
    "ax.text(1,1,'$\\\\theta$')\n",
    "\n",
    "\n",
    "ax.set_xlim(0,5)\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylim(0,5)\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.grid(True,ls=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "B = \\hat{B} + E\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector $\\hat{B}$ is said to be the **projection** of $B$ in the direction of $V$.\n",
    "\n",
    "To find the magnitude of $\\hat{B}$, we can use the definition of cosine to write $|\\hat{B}| = |B|\\cos{\\theta}$.  We also know that $\\cos{\\theta}$ can be determined using the dot product.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\cos{\\theta} = \\frac{B\\cdot V}{|B||V|}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Combining these facts gives us $|\\hat{B}|$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "|\\hat{B}| = \\frac{B\\cdot V}{|V|} \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "We can now construct $\\hat{B}$ by multiplying $|\\hat{B}|$ by a unit vector in the direction of $V$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{B} = \\frac{B\\cdot V}{|V|}\\left(\\frac{V}{|V|}  \\right)  \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Finally, we can give a tidy formula by writing $|V|^2$ using the dot product.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{B} = \\left(\\frac{B\\cdot V}{V\\cdot V}\\right) V \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.8]\n",
      " [1.4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from laguide import DotProduct\n",
    "\n",
    "B = np.array([[2],[3]])\n",
    "V = np.array([[4],[2]])\n",
    "\n",
    "k = DotProduct(B,V)/DotProduct(V,V)\n",
    "\n",
    "B_hat = k*V\n",
    "\n",
    "print(B_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to calculate $E$ is to first find $\\hat{B}$, then set $E = B - \\hat{B}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8]\n",
      " [ 1.6]]\n"
     ]
    }
   ],
   "source": [
    "E = B - B_hat\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the calculations are correct, we should see that $\\hat{B}$ and $E$ are orthogonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.440892098500626e-16\n"
     ]
    }
   ],
   "source": [
    "print(DotProduct(B_hat,E))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see in fact that the computed value of $\\hat{B}\\cdot E$ is not *exactly* zero due to the imprecision of the machine arithmetic.  This is very similar to the some of the results we observed when performing elimination numerically, and we must keep in mind the potential for such errors.  \n",
    "\n",
    "We also note that the formula derived here for $\\hat{B}$ works for for vectors of any dimension.  If $B$ and $V$ are vectors in $\\mathbb{R}^n$, they still occupy a common plane, and the picture looks just the same regardless of the fact that the plane sits in a higher dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gram-Schmidt algorithm\n",
    "\n",
    "Given a set of linearly independent vectors  $\\{V_1, V_2, V_3 ... V_n\\}$, the Gram-Schmidt algorithm produces an orthonormal set of vectors $\\{U_1, U_2, U_3 ... U_n\\}$ such that the span of  $\\{U_1, U_2, U_3 ... U_n\\}$ is the same as the span of  $\\{V_1, V_2, V_3 ... V_n\\}$.  The idea is that we will construct the set of $U$ vectors one at a time by adding in a new $V$ vector to the set after first subtracting the components of $V$ that are in the directions of any $U$ vectors already in the set.  The $U$ vectors can be scaled to unit length as part of the process, or they can all be scaled at the end, after all of the projections have been computed.\n",
    "\n",
    "We write out the individual steps before providing an example.\n",
    "\n",
    "1. $V_1$ is scaled to unit length and becomes $U_1$.\n",
    "2. The projection of $V_2$ in the direction of $U_1$ is subtracted from $V_2$.  This vector is scaled to unit length and becomes $U_2$.\n",
    "3. The projections of $V_3$ in the directions of $U_1$ and $U_2$ are subtracted from $V_3$.  This vector is scaled to unit length and becomes $U_3$.  \n",
    "4. Continue for all $n$ vectors.\n",
    "\n",
    "In general, the projections of $V_k$ in the directions of $U_1$, $U_2$, ...$U_{k-1}$ are subtracted from $V_k$ and the vector that results is scaled to unit length to become $U_k$.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "As a first example, we take three vectors from $\\mathbb{R}^3$ as the starting set, and use Python to carry out the calculations.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "V_1 = \\left[ \\begin{array}{r} 1 \\\\ 2 \\\\ 0 \\end{array}\\right] \\hspace{0.7cm} \n",
    "V_2 = \\left[ \\begin{array}{r} 1 \\\\ 1 \\\\ 1 \\end{array}\\right] \\hspace{0.7cm}\n",
    "V_3 = \\left[ \\begin{array}{r} 3 \\\\ 0 \\\\ 1 \\end{array}\\right] \\hspace{0.7cm}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The first vector, $V_1$ is scaled to unit legth to become $U_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4472136 ]\n",
      " [0.89442719]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "V_1 = np.array([[1],[2],[0]])\n",
    "V_2 = np.array([[1],[1],[1]])\n",
    "V_3 = np.array([[3],[0],[1]])\n",
    "\n",
    "V_1_length = sqrt(DotProduct(V_1,V_1))\n",
    "U_1 = V_1/V_1_length\n",
    "print(U_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build $U_2$, we first subtract from $V_2$ the projection of $V_2$ in the direction of $U_1$ and then scale the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.36514837]\n",
      " [-0.18257419]\n",
      " [ 0.91287093]]\n"
     ]
    }
   ],
   "source": [
    "W_2 = V_2 - (DotProduct(V_2,U_1))*U_1\n",
    "W_2_length = sqrt(DotProduct(W_2,W_2))\n",
    "U_2 = W_2/W_2_length\n",
    "print(U_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we labeled the intermediate result as $W_2$ in order to break the computation into shorter steps.\n",
    "\n",
    "In the final step, we subtract from $V_3$ the projections of $V_3$ in the directions of $U_1$ and $U_2$, and then scale the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.81649658]\n",
      " [-0.40824829]\n",
      " [-0.40824829]]\n"
     ]
    }
   ],
   "source": [
    "W_3 = V_3 - (DotProduct(V_3,U_1))*U_1 - (DotProduct(V_3,U_2))*U_2\n",
    "W_3_length = sqrt(DotProduct(W_3,W_3))\n",
    "U_3 = W_3/W_3_length\n",
    "print(U_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check now that the $U$ vectors are mutually orthogonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.551115123125783e-17\n",
      "0.0\n",
      "-5.551115123125783e-17\n"
     ]
    }
   ],
   "source": [
    "print(DotProduct(U_1,U_2))\n",
    "print(DotProduct(U_1,U_3))\n",
    "print(DotProduct(U_2,U_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing this example, we write down the process in a more formulaic manner.  For each $i = 1, 2, ... n$, we set\n",
    "\n",
    "$W_i = V_i - (V_i \\cdot U_1)U_1 - (V_i\\cdot U_2)U_2 ... - (V_i\\cdot U_{i-1})U_{i-1}$  \n",
    "$U_i = W_i/|W_i|$  \n",
    "\n",
    "It is important to notice here that in general $U_i$ is a linear combination of $\\{V_1, V_2, ..., V_{i}\\}$.  This means that not only is it true that the span of $\\{U_1, U_2, U_3 ... U_n\\}$ is equal to the span of $\\{V_1, V_2, V_3 ..., V_n\\}$, but also it is true that the span of $\\{U_1, U_2, ..., U_i\\}$ is equal to the span of $\\{V_1, V_2, ..., V_i\\}$ at every step of the process.  This has important implications for the application presented in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal matrices\n",
    "\n",
    "Another way we could check that the set of vectors $\\{U_1, U_2, U_3\\}$ is orthonormal is to assemble a matrix with these vectors as the columns and take advantage of the connection between matrix multiplications and dot products.  Suppose that $Q$ is the matrix with $U_1$, $U_2$, and $U_3$ as its columns.  If we compute the matrix product $Q^TQ$, the entries will be the dot products between the rows of $Q^T$ and columns of $Q$, both of which are the set of $U$ vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4472136   0.36514837  0.81649658]\n",
      " [ 0.89442719 -0.18257419 -0.40824829]\n",
      " [ 0.          0.91287093 -0.40824829]]\n",
      "[[ 1.00000000e+00  5.55111512e-17  0.00000000e+00]\n",
      " [ 5.55111512e-17  1.00000000e+00 -5.55111512e-17]\n",
      " [ 0.00000000e+00 -5.55111512e-17  1.00000000e+00]]\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  1. -0.]\n",
      " [ 0. -0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "Q = np.hstack((U_1,U_2,U_3))\n",
    "print(Q)\n",
    "I = Q.transpose()@Q\n",
    "print(Q.transpose()@Q)\n",
    "print(np.around(I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that $U_i\\cdot U_j$ is 0 if $i\\neq j$ and 1 if $i=j$, which means that $Q^TQ$ is the identity matrix $I$.\n",
    "\n",
    "The matrix $Q$ is called an **orthogonal matrix**, which means that its columns form a set of orthonormal vectors.  The immediate result is that if $Q$ is an orthogonal matrix, then $Q^TQ = I$.  In the special case that $Q$ is square, this equation implies that $Q^T = Q^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "- Derive the formula for the projection of $B$ onto $V$ in another way that doesn't involve $\\cos{\\theta}$.  Let $\\hat{B} = kV$, where $k$ is an unknown scalar.  Now use $\\hat{B}\\cdot E$ directly to determine $k$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
