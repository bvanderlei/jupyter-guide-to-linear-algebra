{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QR Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Chapter 1 we saw that the LU factorization essentially captured the elimination process and stored the result in a way that allowed us to use elimination to solve similar systems without having to carry out the elimination again.  The QR factorization does accomplishes something similar for the orthogonalization process.  Given a matrix $A$ with linearly independent columns, the QR factorization of $A$ is a pair of matrices $Q$ and $R$ such that $Q$ is orthogonal, $R$ is upper triangular, and $QR=A$.\n",
    "If $A$ is an $m\\times n$ matrix with linearly independent columns, it must be that $m \\ge n$.  $Q$ then will be $m\\times n$ with orthonormal columns, and $R$ will be $n\\times n$ and upper triangluar.  Suppose for example that $A$ has 6 rows and 4 columns.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A =  \\left[ \\begin{array}{c|c|c|c} & & & \\\\\n",
    "A_1 & A_2 & A_3 & A_4 \\\\ & & & \\end{array} \\right] \\hspace{2cm}\n",
    "Q =  \\left[ \\begin{array}{c|c|c|c} & & & \\\\\n",
    "U_1 & U_2 & U_3 & U_4 \\\\ & & & \\end{array} \\right] \\hspace{2cm}\n",
    "R = \\left[ \\begin{array}{cccc} * & * & * & * \\\\ 0 & * & * & * \\\\ 0 & 0 & * & * \\\\ 0 & 0 & 0 & *  \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The columns of $Q$ are the result of applying the orthogonalization process to the columns of $A$.  If we suppose that this is the case, let's explain why $R$ must be triangular by looking at the product $QR$ one column at a time.  For the first column we have the following vector equation which specifies the linear combination of the $U$ vectors that form $A_1$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\left[ \\begin{array}{c|c|c|c} & & & \\\\\n",
    "U_1 & U_2 & U_3 & U_4 \\\\ & & & \\end{array} \\right]\n",
    "\\left[ \\begin{array}{c} r_{11} \\\\ r_{21} \\\\ r_{31} \\\\ r_{41} \\end{array} \\right]\n",
    "= r_{11}U_1 + r_{21}U_2 + r_{31}U_3 + r_{41}U_4 = A_1\n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know however that $U_1$ is the unit vector in the direction of $A_1$.  This means that $r_{21}=r_{31}=r_{41}=0$ and \n",
    "$r_{11} = |A_1|$.  Let's also note that  $|A_1| = U_1\\cdot A_1$.\n",
    "\n",
    "For the second column we have a similar equation.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\left[ \\begin{array}{c|c|c|c} & & & \\\\\n",
    "U_1 & U_2 & U_3 & U_4 \\\\ & & & \\end{array} \\right]\n",
    "\\left[ \\begin{array}{c} r_{12} \\\\ r_{22} \\\\ r_{32} \\\\ r_{42} \\end{array} \\right]\n",
    "= r_{12}U_1 + r_{22}U_2 + r_{32}U_3 + r_{42}U_4 = A_2\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "We know from the orthogonalization process that $U_2$ is built by subtracting from $A_2$ the component that is in the $U_1$ direction.  Thus, $A_2$ is a linear combination of $U_1$ and $U_2$.  This means that $r_{32}=r_{42}=0$ and $r_{12}$ and $r_{22}$ are the coordinates of $A_2$ with respect to $U_1$ and $U_2$, which we can compute as $r_{12} = U_1\\cdot A_2$ and \n",
    "$r_{22} = U_2\\cdot A_2$.\n",
    "\n",
    "Carrying out the same reasoning for the last two columns, we find that in general $r_{ij} = U_i\\cdot A_j$ and that $r_{ij} = 0$ for $i>j$ because the span of $\\{U_1, U_2, ..., U_i\\}$ is equal to the span of $\\{A_1, A_2, ..., A_i\\}$.\n",
    "\n",
    "To arrive at this conclusion this more succinctly, we could multiply the equation $A=QR$ by $Q^T$, which gives $Q^TA=Q^TQR$ and $Q^TA = R$ since $Q^TQ = I$.  If we then understand the matrix product $Q^TA$ as a collection of dot products between rows of $Q^T$ and columns of $A$, we have again that $r_{ij} = U_i \\cdot A_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "Let's compute the QR factorization for a specific $6\\times 4 $ matrix.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A = \\left[ \\begin{array}{rrrr} \n",
    "1 & 3 & 2 & 0 \\\\ \n",
    "0 & -1 & -1 & 0 \\\\ \n",
    "2 & 2 & 1 & 1 \\\\\n",
    "-1 & 1 & 3 & 4 \\\\\n",
    "-4 & 0 & 1 & -2 \\\\\n",
    "0 & -1 & -2 & 5 \\\\\n",
    "\\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  2  0]\n",
      " [ 0 -1 -1  0]\n",
      " [ 2  2  1  1]\n",
      " [-1  1  3  4]\n",
      " [-4  0  1 -2]\n",
      " [ 0 -1 -2  5]]\n",
      "[[ 1.  0. -0.  0.]\n",
      " [ 0.  1. -0.  0.]\n",
      " [-0. -0.  1.  0.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[[ 0.21320072  0.71960864 -0.32643805  0.03625532]\n",
      " [ 0.         -0.2638565   0.01525411 -0.00954087]\n",
      " [ 0.42640143  0.38379127 -0.10982963  0.09922508]\n",
      " [-0.21320072  0.33581737  0.74745161  0.52474801]\n",
      " [-0.85280287  0.28784346 -0.32338723 -0.07251063]\n",
      " [ 0.         -0.2638565  -0.46677591  0.84150499]]\n",
      "\n",
      "\n",
      "[[ 4.69041576e+00  1.27920430e+00 -6.39602149e-01  1.27920430e+00]\n",
      " [ 5.55111512e-16  3.78993883e+00  3.90987361e+00 -1.67908683e-01]\n",
      " [-1.22124533e-15 -1.77635684e-15  2.07455958e+00  1.19287176e+00]\n",
      " [ 4.44089210e-16  3.33066907e-16  3.88578059e-16  6.55076331e+00]]\n",
      "\n",
      "\n",
      "[[ 1.  3.  2. -0.]\n",
      " [-0. -1. -1. -0.]\n",
      " [ 2.  2.  1.  1.]\n",
      " [-1.  1.  3.  4.]\n",
      " [-4.  0.  1. -2.]\n",
      " [ 0. -1. -2.  5.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from laguide import DotProduct as Dot\n",
    "from laguide import Magnitude\n",
    "\n",
    "# Define A\n",
    "A = np.array([[1, 3, 2, 0], [0, -1, -1, 0], [2, 2, 1, 1], [-1, 1, 3, 4],[-4, 0, 1, -2],[0, -1, -2, 5]])\n",
    "print(A)\n",
    "\n",
    "# Slice out the colums of A for processing\n",
    "A_1 = A[:,0:1]\n",
    "A_2 = A[:,1:2]\n",
    "A_3 = A[:,2:3]\n",
    "A_4 = A[:,3:4]\n",
    "\n",
    "# Carry out Gram-Schmidt process\n",
    "U_1 = A_1/Magnitude(A_1)\n",
    "W_2 = A_2 - Dot(A_2,U_1)*U_1\n",
    "U_2 = W_2/Magnitude(W_2)\n",
    "W_3 = A_3 - Dot(A_3,U_1)*U_1 - Dot(A_3,U_2)*U_2\n",
    "U_3 = W_3/Magnitude(W_3)\n",
    "W_4 = A_4 - Dot(A_4,U_1)*U_1 - Dot(A_4,U_2)*U_2 - Dot(A_4,U_3)*U_3\n",
    "U_4 = W_4/Magnitude(W_4)\n",
    "\n",
    "# Assemble the matrix Q\n",
    "\n",
    "Q = np.hstack((U_1,U_2,U_3,U_4))\n",
    "\n",
    "# Check that Q is orthogonal\n",
    "\n",
    "print(np.around(Q.transpose()@Q))\n",
    "\n",
    "# Compute R\n",
    "\n",
    "R = Q.transpose()@A\n",
    "\n",
    "#  Check\n",
    "\n",
    "print(Q)\n",
    "print('\\n')\n",
    "print(R)\n",
    "print('\\n')\n",
    "print(np.around(Q@R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course if we want carry out the factorization in general, it would be helpful to write the code in more general way, and tuck it into a function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QRFactorization(A):\n",
    "    # =============================================================================\n",
    "    # A is a Numpy array that represents a matrix of dimension m x n.\n",
    "    # QRFactorization returns matrices Q and R such that A=QR, Q is orthogonal\n",
    "    # and R is upper triangular.  The factorization is carried out using classical\n",
    "    # Gram-Schmidt and the results may suffer due to numerical instability.\n",
    "    # QRFactorization may not return correct results if the columns of A are \n",
    "    # linearly dependent.\n",
    "    # =============================================================================\n",
    "\n",
    "    # Check shape of A\n",
    "    if (A.shape[0] < A.shape[1]):\n",
    "        print(\"A must have more rows than columns for QR factorization.\")\n",
    "        return\n",
    "\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    \n",
    "    Q = np.zeros((m,n))\n",
    "    R = np.zeros((n,n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        W = A[:,i:i+1]\n",
    "        for j in range(i):\n",
    "                W = W - Dot(A[:,i:i+1],Q[:,j:j+1])*Q[:,j:j+1]\n",
    "        Q[:,i:i+1] = W/Magnitude(W)\n",
    "        \n",
    "    R = Q.transpose()@A\n",
    "    \n",
    "    return (Q,R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One point to note here is that this function returns the pair of matrices $Q$ and $R$.  In order to receive both results, we need to assign a pair of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21320072  0.71960864 -0.32643805  0.03625532]\n",
      " [ 0.         -0.2638565   0.01525411 -0.00954087]\n",
      " [ 0.42640143  0.38379127 -0.10982963  0.09922508]\n",
      " [-0.21320072  0.33581737  0.74745161  0.52474801]\n",
      " [-0.85280287  0.28784346 -0.32338723 -0.07251063]\n",
      " [ 0.         -0.2638565  -0.46677591  0.84150499]]\n",
      "\n",
      "\n",
      "[[ 4.69041576e+00  1.27920430e+00 -6.39602149e-01  1.27920430e+00]\n",
      " [ 5.55111512e-16  3.78993883e+00  3.90987361e+00 -1.67908683e-01]\n",
      " [-1.22124533e-15 -1.77635684e-15  2.07455958e+00  1.19287176e+00]\n",
      " [ 4.44089210e-16  3.33066907e-16  3.88578059e-16  6.55076331e+00]]\n"
     ]
    }
   ],
   "source": [
    "Q,R = QRFactorization(A)\n",
    "print(Q)\n",
    "print('\\n')\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving a Linear System \n",
    "\n",
    "It turns out that the orthogonalization behind the $QR$ factorization also provides another way to solve a linear system $AX=B$.  If we substitute $A=QR$, then multiply the equation by $Q^T$, we get $Q^TQRX = Q^TB$.  Once again $Q^TQ$ simplifys to $I$, so we are left with $RX=Q^TB$, which is a triangular system that can be solved easily by back substitution.\n",
    "\n",
    "Let's try it out on a $4\\times 4$ system.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\left[ \\begin{array}{rrrr} \n",
    "2 & 3 & 0 & -1 \\\\ \n",
    "-1 & 0 & 2 & 0 \\\\ \n",
    "-1 & -1 & 4 & 2 \\\\\n",
    "0 & 3 & -3 & 2 \\\\\n",
    "\\end{array}\\right]X = \n",
    "\\left[ \\begin{array}{r} 0 \\\\ 1 \\\\ 2 \\\\ 5 \\end{array} \\right]\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  3  0 -1]\n",
      " [-1  0  2  0]\n",
      " [-1 -1  4  2]\n",
      " [ 0  3 -3  2]]\n",
      "[[-1.00000000e+00]\n",
      " [ 1.00000000e+00]\n",
      " [-1.75198215e-16]\n",
      " [ 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from laguide import BackSubstitution\n",
    "\n",
    "A = np.array([[2, 3, 0, -1],[-1, 0, 2, 0],[-1, -1, 4, 2],[0, 3, -3, 2]])\n",
    "print(A)\n",
    "B = np.array([[0],[1],[2],[5]])\n",
    "X = np.array([[-1],[1],[0],[1]])\n",
    "Q,R = QRFactorization(A)\n",
    "C = Q.transpose()@B\n",
    "X = BackSubstitution(R,C)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some situations, we might find that we are solving several systems such as $AX=B_1$, $AX=B_2$, $AX=B_3$, ..., that involve the same matrix but different right hand sides.  In these situations it is useful to solve the systems with a factorization such as $QR$ or $LU$, because the factorization does not need to be recomputed for each system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
