{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "259ae74d",
   "metadata": {},
   "source": [
    "## Inner Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d30603f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import laguide as lag\n",
    "import numpy as np\n",
    "import scipy.linalg as sla\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a6e1d9",
   "metadata": {},
   "source": [
    "**Exercise 1:** Create a Python function named $\\texttt{Magnitude}$ that accepts as an argument vector in the form of a NumPy array object with shape $n\\times 1$, and returns the magnitude of that vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8efd745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Magnitude(U):\n",
    "    ''' \n",
    "    Magnitude(U)\n",
    "    \n",
    "    Magnitude computes the magnitude of U based on the Euclidean inner product\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    U : NumPy array object of dimension nx1\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    product: float\n",
    "    '''\n",
    "    # Check shape of U\n",
    "    if (U.shape[1] != 1):\n",
    "        print(\"Magnitude only accepts column vectors.\")\n",
    "        return\n",
    "    \n",
    "    magnitude = math.sqrt(DotProduct(U,U))\n",
    "    return magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ce8f0",
   "metadata": {},
   "source": [
    "**Exercise 2:** Use the $\\texttt{random}$ module of NumPy to generate random $4\\times 1$ vectors $U$, $V$, and $W$, and a random scalar $k$.  Verify the algebraic properties of the dot product listed above.  Try to make use of a conditional statement to check each statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd78294",
   "metadata": {},
   "source": [
    "We want to verify that the following equations hold for random $4 \\times 1$ vectors $U, V,$ and $W$ and scalar $k$.\n",
    "1. $U\\cdot V = V\\cdot U$\n",
    "2. $U\\cdot(V + W) = U\\cdot V + U\\cdot W$\n",
    "3. $(kU)\\cdot V = k(U\\cdot V)$\n",
    "4. $U\\cdot U \\ge 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e5ba92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7]\n",
      " [19]\n",
      " [11]\n",
      " [11]] \n",
      "\n",
      "[[8]\n",
      " [0]\n",
      " [6]\n",
      " [1]] \n",
      "\n",
      "[[12]\n",
      " [14]\n",
      " [12]\n",
      " [18]] \n",
      "\n",
      "9 \n",
      "\n",
      "The dot product is commutative. \n",
      "\n",
      "The dot product distributes over vector addition. \n",
      "\n",
      "The dot product is associative with respect to scalar multiplication. \n",
      "\n",
      "The dot product of a vector with itself is greater than or equal to 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "U = np.random.randint(20,size=(4,1))\n",
    "V = np.random.randint(20,size=(4,1))\n",
    "W = np.random.randint(20,size=(4,1))\n",
    "k = np.random.randint(20)\n",
    "\n",
    "print(U,'\\n')\n",
    "print(V,'\\n')\n",
    "print(W,'\\n')\n",
    "print(k,'\\n')\n",
    "\n",
    "if (lag.DotProduct(U,V) == lag.DotProduct(V,U)):\n",
    "    print(\"The dot product is commutative. \\n\")\n",
    "if (lag.DotProduct(U,V+W) == lag.DotProduct(U,V) + lag.DotProduct(U,W)):\n",
    "    print(\"The dot product distributes over vector addition. \\n\")\n",
    "if (lag.DotProduct(k*U,V) == k*lag.DotProduct(U,V)):\n",
    "    print(\"The dot product is associative with respect to scalar multiplication. \\n\")\n",
    "if (lag.DotProduct(U,U) >= 0):\n",
    "    print(\"The dot product of a vector with itself is greater than or equal to 0 \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e420d5",
   "metadata": {},
   "source": [
    "**Exercise 3:** Let $X$ and $Y$ be the following vectors.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X = \\left[ \\begin{array}{r} 3 \\\\ -1 \\\\ 2  \\end{array}\\right] \\hspace{1cm} \n",
    "Y = \\left[ \\begin{array}{r} 4 \\\\ 2 \\\\ 0  \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$(a)$ Determine the angle between $X$ and $Y$.  (*You will need the $\\texttt{acos}$ function in Python's $\\texttt{math}$ module.*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a00fb83",
   "metadata": {},
   "source": [
    "We will use the following equation to determine the angle $\\theta$ between $X$ and $Y$, as well as the $\\texttt{DotProduct}$ and $\\texttt{Magnitude}$ functions.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\cos{\\theta} = \\frac{X\\cdot Y}{||X||||Y||}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df21142e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9302740141154721\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[3],[-1],[2]])\n",
    "Y = np.array([[4],[2],[0]])\n",
    "print(math.acos((lag.DotProduct(X,Y))/((lag.Magnitude(X))*(lag.Magnitude(Y)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d294fb",
   "metadata": {},
   "source": [
    "$(b)$ Find a vector in $\\mathbb{R}^3$ that is orthogonal to the vector $X$.  Verify your answer with a computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49511fb",
   "metadata": {},
   "source": [
    "Two vectors are **orthogonal** if their dot product is zero. The vector $W$ defined below is an example of a vector that is orthogonal to $X$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "W = \\left[ \\begin{array}{r} 1 \\\\ 3 \\\\ 0  \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e18b64bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[3],[-1],[2]])\n",
    "W = np.array([[1],[3],[0]])\n",
    "print(lag.DotProduct(X,W))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518695fd",
   "metadata": {},
   "source": [
    "$(c)$ Construct a unit vector $Z$ such that $Z\\cdot Y = -||Y||$.  Verify your answer with a computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd076c2",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Recall that if $\\theta$ is the angle between $Z$ and $Y$, then the following equation is an identity.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{Z\\cdot Y}{||Z||||Y||} = \\cos\\theta\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Since we want $Z$ to be a unit vector, $||Z|| = 1$ and so we can rearrange to get\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Z\\cdot Y = ||Y||\\cos{\\theta} \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "From here we can see that $Z \\cdot Y = -||Y||$ precisely when $\\theta = \\pi$ or in other words, when $Z$ is a unit vector pointing in the opposite direction of $Y$. To find such a $Z$, we can take any vector that points in the direction opposite to $Y$ ($-Y$ for example) and divide by its magnitude. Therefore\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Z = \\frac{-Y}{||-Y||} = \\frac{1}{\\sqrt{20}} \\left[ \\begin{array}{r} -4 \\\\ -2 \\\\ 0  \\end{array}\\right] = \\left[ \\begin{array}{r} \\frac{-2\\sqrt{5}}{5} \\\\ -\\frac{\\sqrt{5}}{5} \\\\ 0  \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a06b25e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.47213595499958 \n",
      "\n",
      "-4.47213595499958 \n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "Y = np.array([[4],[2],[0]])\n",
    "Z = np.array([[-2*np.sqrt(5)/5],[-np.sqrt(5)/5],[0]])\n",
    "print(lag.DotProduct(Z,Y),'\\n')\n",
    "print(-lag.Magnitude(Y),'\\n')\n",
    "print(lag.Magnitude(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781a1813",
   "metadata": {},
   "source": [
    "**Alternate Solution:**\n",
    "\n",
    "First we calculate $-||Y|| = -\\sqrt{4^2 + 2^2 + 0^2} = -2\\sqrt{5}$. If we define the arbitrary vector $Z$ as below, then we see that we need to find values for $z_1, z_2$, and $z_3$ such that $||Z|| = \\sqrt{(z_1)^2 + (z_2)^2 + (z_3)^2} = 1$ and $Z \\cdot Y = 4z_1 + 2z_2 + 0z_3 = -2\\sqrt{5}$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Z = \\left[ \\begin{array}{r} z_1 \\\\ z_2 \\\\ z_3  \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Since $z_3$ contributes nothing to the second sum above, lets set $z_3 = 0$ for simplicities sake. This gives a system of two equations in two unknowns, namely\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "4z_1 + 2z_2 & = & -2\\sqrt{5} \\\\\n",
    "z_1^2 + z_2^2 & = & 1 \\\\\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Note that we can't solve this system using elimination because the second equation is not linear.  Instead, if we solve for one of the variables in the first equation and substitute into the second, we will be able to use the quadratic formula to find a solution. Solving for $z_2$ in the first equation, we get\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "z_2 & = & -\\sqrt{5} - 2z_1 \\\\\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Next we substitute this equality in for $z_2$ in our second equation, multiply out and move everything to the left.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "5z_1^2 + 4\\sqrt{5}z_1 + 4 = 0 \\\\\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Using the quadratic formula reveals that the two roots of this equation are equal, namely $z_1 = -\\frac{2}{5}\\sqrt{5}$. If we substitute this into the equation above where we had solved for $z_2$, we see that $z_2 = -\\frac{1}{5}\\sqrt{5}$ and thus the vector $Z$ below is a solution to our problem.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Z = \\left[ \\begin{array}{r} -\\frac{2\\sqrt{5}}{5} \\\\ -\\frac{\\sqrt{5}}{5} \\\\ 0  \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f259903d",
   "metadata": {},
   "source": [
    "**Exercise 4:** Create a Python function named $\\texttt{DifferenceMagnitude}$ which takes two $n \\times 1$ vectors as arguments and returns the magnitude of their difference. Use this function to determine $|| X - Y||$ where vectors $X$ and $Y$ are given below.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X = \\left[ \\begin{array}{r} 3 \\\\ -1 \\\\ 2  \\end{array}\\right] \\hspace{1cm} \n",
    "Y = \\left[ \\begin{array}{r} 4 \\\\ 2 \\\\ 0  \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bebf9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7416573867739413\n"
     ]
    }
   ],
   "source": [
    "# Building the function Difference Magnitude where X and y are two column vectors.\n",
    "\n",
    "def DifferenceMagnitude(X,Y):\n",
    "    Z = X - Y\n",
    "    diffMag = math.sqrt(lag.DotProduct(Z,Z))\n",
    "    return diffMag\n",
    "\n",
    "X = np.array([[3],[-1],[2]])\n",
    "Y = np.array([[4],[2],[0]])\n",
    "\n",
    "print(DifferenceMagnitude(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb80d7",
   "metadata": {},
   "source": [
    "We can see from the computations that $||X - Y|| = 3.714$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b4318",
   "metadata": {},
   "source": [
    "**Exercise 5:** Create a Python function which takes an $n \\times 1$ vector as its argument and returns the unit vector of the argument vector. Use the NumPy $\\texttt{random}$ module to generate a random $3 \\times 1 $ vector, and test this function on that vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eecb360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      " [[5]\n",
      " [6]\n",
      " [8]] \n",
      "\n",
      "The unit vector of X: \n",
      " [[0.4472136 ]\n",
      " [0.53665631]\n",
      " [0.71554175]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Creating the UnitVector function\n",
    "\n",
    "def UnitVector(X):\n",
    "    mag = math.sqrt(lag.DotProduct(X,X))\n",
    "    unitVect = X/mag\n",
    "    \n",
    "    return unitVect\n",
    "\n",
    "## Building a random vector\n",
    "X = np.random.randint(10,size = (3,1))\n",
    "print(\"X: \\n\" , X, '\\n')\n",
    "print(\"The unit vector of X: \\n\", UnitVector(X), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770afd2a",
   "metadata": {},
   "source": [
    "**Exercise 6:** Find a vector $Y$ in $\\mathbb{R}^2$ such that $X\\cdot Y = ||Y - X||$ where the vector $X$ is given below. Is the vector $Y$ unique ? Verify your answer through a computation.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X = \\left[ \\begin{array}{r} 1 \\\\ 1  \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd891a",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Let us assume that the vector $Y$ in $\\mathbb{R}^2$ is as follows:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Y = \\left[ \\begin{array}{r} a \\\\ b  \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "where $a$, $b$ are some scalars.\n",
    "\n",
    "\n",
    "So, $$\n",
    "\\begin{equation}\n",
    "Y  - X= \\left[ \\begin{array}{r} a - 1 \\\\ b - 1  \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "$||Y - X||^2 = (a-1)^2 + (b-1)^2 $\n",
    "\n",
    "$X\\cdot Y = a + b$\n",
    "\n",
    "As $X\\cdot Y = ||Y - X||$ , $(X\\cdot Y)^2 = ||Y - X||^2 $.\n",
    "\n",
    "So, $ (a+b)^2 = (a - 1)^2 + (b-1)^2 $\n",
    "\n",
    "$ a^2 + b^2 + 2ab = a^2 + 1 - 2a + b^2 + 1 - 2b$\n",
    "\n",
    "$ 2ab = 2 - 2a - 2b$\n",
    "\n",
    " $2a + 2b + 2ab = 2$\n",
    "\n",
    "$ a + b + ab = 1$\n",
    "\n",
    "The above equation is true for two possible set of real values of $a$ and $b$. First case is when $a = 0$ and $b = 1$, and second case is when $a = 1$ and $b = 0$.\n",
    "\n",
    "Therefore, we get two possible vectors $Y$ which are as follows:\n",
    "\n",
    "So, $$\n",
    "\\begin{equation}\n",
    "Y = \\left[ \\begin{array}{r} 1 \\\\ 0  \\end{array}\\right] \\hspace{1cm} or \\hspace{1cm}\n",
    "Y = \\left[ \\begin{array}{r} 0 \\\\ 1  \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "This implies that the vector $Y$ is not unique. We can verify our results in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9a5ef45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product of X and Y_1 is: \n",
      " 1.0 \n",
      "\n",
      "The magnitude of difference of Y_1 and X is: \n",
      " 1.0 \n",
      "\n",
      "Dot product of X and Y_2 is: \n",
      " 1.0 \n",
      "\n",
      "The magnitude of difference of Y_2 and X is: \n",
      " 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Building vectors X and Y:\n",
    "\n",
    "X = np.array([[1],[1]])\n",
    "Y_1 = np.array([[1],[0]])\n",
    "Y_2 = np.array([[0],[1]])\n",
    "\n",
    "dotProd1 = lag.DotProduct(X, Y_1)\n",
    "dotProd2 = lag.DotProduct(X, Y_2)\n",
    "\n",
    "diffMag1 = DifferenceMagnitude(Y_1, X )\n",
    "diffMag2 = DifferenceMagnitude(Y_2, X)\n",
    "\n",
    "print(\"Dot product of X and Y_1 is: \\n\", dotProd1, '\\n')\n",
    "print(\"The magnitude of difference of Y_1 and X is: \\n\", diffMag1, '\\n')\n",
    "\n",
    "print(\"Dot product of X and Y_2 is: \\n\", dotProd2, '\\n')\n",
    "print(\"The magnitude of difference of Y_2 and X is: \\n\", diffMag2, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f18fd",
   "metadata": {},
   "source": [
    "The computations done in the above code cell demonstrate that the vector $Y$ is not unique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68972910",
   "metadata": {},
   "source": [
    "**Exercise 7:** Create a Python function named $\\texttt{Angle}$ which takes two vectors as arguments and returns $\\cos{\\theta}$ where ${\\theta}$ is the angle between the two vectors. Use this function to show that vectors $U$ and $W$ are orthogonal.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "U = \\left[ \\begin{array}{r} 1 \\\\ -1 \\\\ 2  \\end{array}\\right] \\hspace{1cm} \n",
    "W = \\left[ \\begin{array}{r} 2 \\\\ 0 \\\\ -1  \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "799fdcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "## Building the function Angle\n",
    "\n",
    "def Angle(X,Y):\n",
    "    dotProd = lag.DotProduct(X, Y)\n",
    "    magX = math.sqrt(lag.DotProduct(X, X))\n",
    "    magY = math.sqrt(lag.DotProduct(Y, Y))\n",
    "    cos_theta = dotProd/(magX*magY)\n",
    "    \n",
    "    return cos_theta\n",
    "\n",
    "U = np.array([[1],[-1],[2]])\n",
    "W = np.array([[2],[0],[-1]])\n",
    "\n",
    "print(Angle(U, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072fffc9",
   "metadata": {},
   "source": [
    "We can see that $\\cos{\\theta} = 0$ for vectors $U$ and $W$ which means that $\\theta = 90^{\\circ}$. This implies that $U$ and $W$ are orthogonal vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dafd13",
   "metadata": {},
   "source": [
    "**Exercise 8:** Given that $||X+Y|| = 3$, $X\\cdot Y = 2$, find $||X-Y||$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c8c290",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "We know that $||X + Y||^2 = (X+Y)\\cdot (X+Y)$\n",
    "\n",
    "$||X + Y||^2 = ||X||^2 + ||Y||^2 + 2X\\cdot Y$\n",
    "\n",
    "Given $||X + Y||$ and $X\\cdot Y$,we can find $||X||^2  + ||Y||^2$ as follows:\n",
    "\n",
    "$ (3)^2 = ||X||^2 + ||Y||^2 + 2(2)$\n",
    "\n",
    "$||X||^2 + ||Y||^2 = 5$\n",
    "\n",
    "Now, $||X - Y||^2 = (X-Y)\\cdot (X-Y)$\n",
    "\n",
    "$||X - Y||^2 = ||X||^2 + ||Y||^2 - 2X\\cdot Y$\n",
    "\n",
    "We can now substitute the values for $||X||^2 + ||Y||^2$ and $X\\cdot Y$ to get:\n",
    "\n",
    "$||X - Y||^2 = 5 - 2(2)$\n",
    "\n",
    "$||X - Y||^2 = 1$\n",
    "\n",
    "Therefore, $||X - Y|| = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443a7abb",
   "metadata": {},
   "source": [
    "### Orthogonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a83b3f",
   "metadata": {},
   "source": [
    "**Exercise 1:**  Explain why a set of nonzero mutually orthogonal vectors must be linearly independent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1190216",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Suppose we have some set of mutually orthogonal vectors $\\{U_1,U_2, \\cdots ,U_n\\}$. To say that this set is linearly independent is equivalent to saying that if $a_1U_1 + a_2U_2 + \\cdots a_nU_n = 0$ for some scalars $a_1, a_2, \\cdots , a_n$, then $a_1 = a_2 = \\cdots a_n = 0$. To see that this must be the case, take the dot product of each side of the equation with $U_i$ for each $1 \\leq i \\leq n$. Since the vectors are mutually orthogonal, $U_i \\cdot U_j = 0$ when $i \\neq j$ and thus we get $a_i(U_i \\cdot U_i) = 0$. Therefore $a_i = 0$ for all $1 \\leq i \\leq n$ and so our set of vectors is linearly independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401ce609",
   "metadata": {},
   "source": [
    "**Exercise 2:**  Derive the formula for the projection of $B$ onto $V$ in another way that doesn't involve $\\cos{\\theta}$.  Let $\\hat{B} = kV$, where $k$ is an unknown scalar.  Now use $\\hat{B}\\cdot E$ to determine $k$ directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da1a3c",
   "metadata": {},
   "source": [
    "**Exercise 3:** The set $\\beta = \\{U_1, U_2, U_3\\}$ is an orthonormal basis for $\\mathbb{R}^3$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "U_1 = \\frac{1}{\\sqrt{6}}\\left[ \\begin{array}{r} 2 \\\\ 1 \\\\ 1 \\end{array}\\right] \\hspace{0.7cm} \n",
    "U_2 = \\frac{1}{\\sqrt{2}}\\left[ \\begin{array}{r} 0 \\\\ -1 \\\\ 1 \\end{array}\\right] \\hspace{0.7cm}\n",
    "U_3 = \\frac{1}{\\sqrt{3}}\\left[ \\begin{array}{r} -1 \\\\ 1 \\\\ 1 \\end{array}\\right] \\hspace{0.7cm}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$(a)$ Define $Q$ as the matrix with columns $U_1$, $U_2$, and $U_3$.  Verify that $Q^TQ=I$.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d0e4c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "s2 = math.sqrt(2)\n",
    "s3 = math.sqrt(3)\n",
    "s6 = math.sqrt(6)\n",
    "Q = np.array([[2/s6,0,-1/s3],[1/s6,-1/s2,1/s3],[1/s6,1/s2,1/s3]])\n",
    "print(Q.transpose()@Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f453336",
   "metadata": {},
   "source": [
    "$(b)$ Let $X$ be the following vector, and compute $[X]_{\\beta}$ by solving $Q[X]\n",
    "_{\\beta}= X$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X = \\left[ \\begin{array}{r} 3 \\\\ 1 \\\\ -4 \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b8a43",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Since $Q^TQ = I$, multiplying both sides of the equation above by $Q^T$ on the left gives us $[X]_{\\beta} = Q^TX$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9471dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.22474487]\n",
      " [-3.53553391]\n",
      " [-3.46410162]]\n"
     ]
    }
   ],
   "source": [
    "s2 = math.sqrt(2)\n",
    "s3 = math.sqrt(3)\n",
    "s6 = math.sqrt(6)\n",
    "Q = np.array([[2/s6,0,-1/s3],[1/s6,-1/s2,1/s3],[1/s6,1/s2,1/s3]])\n",
    "X = np.array([[3],[1],[-4]])\n",
    "print(Q.transpose()@X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c5460",
   "metadata": {},
   "source": [
    "**Exercise 4:** Find a vector that is orthogonal to the column space of the matrix $A$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A = \\left[ \\begin{array}{rr} 1 & 2\\\\ 2 & 0 \\\\ 3 & 1\\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107b2c67",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Since there is a pivot in each column of the matrix $A$, the basis for the column space of $A$ consists of the two column vectors. \n",
    "\n",
    "Let \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X_1 = \\left[ \\begin{array}{r} 1 \\\\ 2 \\\\ 3 \\end{array}\\right] \\hspace{1cm}\n",
    "X_2 = \\left[ \\begin{array}{r} 2 \\\\ 0 \\\\ 1 \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Then the basis for the column space of $A$ is $\\{X_1,X_2\\}$. Let us consider a vector $Y$ which is orthogonal to vectors $X_1$, $X_2$. This means that $X_1\\cdot Y = 0$ and $X_2\\cdot Y=0$.\n",
    "\n",
    "Let\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Y = \\left[ \\begin{array}{r} a \\\\ b \\\\ c \\end{array}\\right] \\hspace{1cm} \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $a$, $b$, $c$ are some scalars.\n",
    "\n",
    "The conditions $X_1\\cdot Y = 0$ and $X_2\\cdot Y=0$ gives a system of equations to solve:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "a + 2b + 3c & = & 0\\\\\n",
    "2a\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, + c & = & 0\\\\ \n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Since $c$ is a free variable we let $c = t$, where $t$ is some real number.  From the above two equations, we can then find the values of $a$ and $b$ in terms of $t$.\n",
    "\n",
    "$a = -t/2$  and $b = -5t/4$.\n",
    "\n",
    "\n",
    "Therefore, the vector $Y$ is as follows:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Y = t\\left[ \\begin{array}{r} -1/2 \\\\ -5/4 \\\\ 1 \\end{array}\\right] \\hspace{1cm} \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "So, one particular vector orthogonal to the column space of $A$ is:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\left[ \\begin{array}{r} -1/2 \\\\ -5/4 \\\\ 1 \\end{array}\\right] \\hspace{1cm} \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b960649",
   "metadata": {},
   "source": [
    "**Exercise 5:** Let $\\mathcal{U}$ be the subspace spanned by $\\{V_1,V_2\\}$. Apply the Gram-Schimdt orthogonalization on the basis $\\{V_1,V_2\\}$ to produce an orthonormal basis $\\{U_1,U_2\\}$ for $\\mathcal{U}$.  Verify that $\\{U_1,U_2\\}$ is an orthonormal basis with a computation.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "V_1 = \\left[ \\begin{array}{r} 1 \\\\ 1 \\\\ 2 \\end{array}\\right] \\hspace{1cm}\n",
    "V_2 = \\left[ \\begin{array}{r} 2 \\\\ 1 \\\\ 3 \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fc057d",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "We first produce an orthogonal basis, $\\{W_1,W_2\\}$, for $\\mathcal{U}$, then scale the orthogonal vectors to produce an orthonormal basis $\\{U_1,U_2\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716fed73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_1: \n",
      " [[0.40824829]\n",
      " [0.40824829]\n",
      " [0.81649658]] \n",
      "\n",
      "u_2: \n",
      " [[ 0.70710678]\n",
      " [-0.70710678]\n",
      " [ 0.        ]] \n",
      "\n",
      "The dot product of u_1 and u_2 is: \n",
      " 0.0 \n",
      "\n",
      "The magnitude of u_1 is: \n",
      " 1.0 \n",
      "\n",
      "The magnitude of u_2 is: \n",
      " 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Generating the orthogonal vectors w_1 and w_2:\n",
    "\n",
    "v_1 = np.array([[1],[1],[2]])\n",
    "v_2 = np.array([[2],[1],[3]])\n",
    "\n",
    "w_1 = v_1 \n",
    "w_2 = v_2 - (lag.DotProduct(w_1, v_2)/lag.DotProduct(w_1, w_1))*w_1\n",
    "\n",
    "# Generating the orthonormal vectors by scaling the orthogonal vectors:\n",
    "\n",
    "u_1 = w_1/math.sqrt(lag.DotProduct(w_1,w_1))\n",
    "u_2 = w_2/math.sqrt(lag.DotProduct(w_2,w_2))\n",
    "\n",
    "print(\"u_1: \\n\", u_1, '\\n')\n",
    "print(\"u_2: \\n\", u_2, '\\n')\n",
    "\n",
    "# Verifying that u_1 and u_2 are orthonormal.\n",
    "\n",
    "print(\"The dot product of u_1 and u_2 is: \\n\", lag.DotProduct(u_1,u_2),'\\n')\n",
    "print(\"The magnitude of u_1 is: \\n\", math.sqrt(lag.DotProduct(u_1,u_1)), '\\n')\n",
    "print(\"The magnitude of u_2 is: \\n\", np.round(math.sqrt(lag.DotProduct(u_2,u_2)), 2), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d65eed",
   "metadata": {},
   "source": [
    "**Exercise 6:** Let $\\mathcal{U}$ be the subspace spanned by $\\{X_1,X_2\\}$. Apply the Gram-Schimdt orthogonalization on the basis $\\{X_1,X_2\\}$ to produce an orthonormal basis $\\{U_1,U_2\\}$ for $\\mathcal{U}$.  Verify that $\\{U_1,U_2\\}$ is an orthonormal basis with a computation.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X_1 = \\left[ \\begin{array}{r} 1 \\\\ 0 \\\\ 2 \\\\ 2 \\end{array}\\right] \\hspace{0.7cm} \n",
    "X_2 = \\left[ \\begin{array}{r} -2 \\\\ 1 \\\\ 0 \\\\ -1 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ac0747",
   "metadata": {},
   "source": [
    "**Exercise 7:** Let $V$ be a vector in $\\mathbb{R}^4$. Explain why the set of vectors orthogonal to $V$ is a subspace of $\\mathbb{R}^4$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f05fdff",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Let $U$ be the set of all vectors which are orthogonal to the vector $v$. Let us consider two vectors $x$ and $y$ in $U$.\n",
    "\n",
    "The vectors $v$, $x$ and $y$ are as follows:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "v = \\left[ \\begin{array}{r} v_1 \\\\ v_2 \\\\ v_3 \\\\ v_4 \\end{array}\\right] \\hspace{1cm}\n",
    "x = \\left[ \\begin{array}{r}  x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{array}\\right] \\hspace{1cm}\n",
    "y = \\left[ \\begin{array}{r}  y_1 \\\\ y_2 \\\\ y_3 \\\\ y_4 \\end{array}\\right] \\hspace{1cm}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "where all the enteries are some scalars.\n",
    "\n",
    "\n",
    "Since vectors $x$ and $y$ are in $U$, the vectors $x$ and $y$ need to be orthogonal to the vector $v$. This basically means that $x\\cdot v = 0$ and $y\\cdot v = 0$.\n",
    "\n",
    "\n",
    "So, $x_1v_1 + x_2v_2 +x_3v_3 + x_4v_4 = 0$ ,\n",
    "\n",
    "$y_1v_1 + y_2v_2 +y_3v_3 + y_4v_4 = 0$.\n",
    "\n",
    "On adding the two equations, we get\n",
    "\n",
    "$(x_1 + y_1)v_1 + (x_2 + y_2)v_2 + (x_3 + y_3)v_3 + (x_4 + y_4)v_4 = 0$\n",
    "\n",
    "The *LHS* is actually the dot product of vector $(x+y)$ with $v$ and since the dot product of vector $(x + y)$ with $v$ equals 0, $(x+y)$ is also in $U$.\n",
    "\n",
    "\n",
    "On multiplying the equation $x_1v_1 + x_2v_2 +x_3v_3 + x_4v_4 = 0$ by $k$ on both sides, we get:\n",
    "\n",
    "\n",
    "$kx_1v_1 + kx_2v_2 + kx_3v_3 + kx_4v_4 = k(0) = 0$\n",
    "\n",
    "The *LHS* of the above equation is basically the dot product of $kx$ and $v$ which also equals zero. Therefore, $kx$ is orthogonal to $v$ and hence, $kx$ is also present in $U$.\n",
    "\n",
    "\n",
    "This imples that for any two vectors $x$ and $y$ in $U$, vectors $(x+y)$ and $kx$ are also present in $U$. This satisfies the condition for a subspace and therefore, $U$ is a subspace of $\\mathbb{R}^4$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c848fc",
   "metadata": {},
   "source": [
    "**Exercise 8:** Given vectors $V$ and $W$, find vectors $X$ and $Y$ such that $X$ is the projection of $V$ in the direction of $W$ and $V = X + Y$. Verify your answer.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "V = \\left[ \\begin{array}{r} \n",
    "9\\\\ 5 \\\\ 0 \\end{array}\\right] \\hspace{1cm}\n",
    "W = \\left[ \\begin{array}{r} 3 \\\\ 0 \\\\ 3 \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a5d3852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      " [[2.38235294]\n",
      " [0.        ]\n",
      " [3.97058824]] \n",
      "\n",
      "Y: \n",
      " [[ 6.61764706]\n",
      " [ 5.        ]\n",
      " [-3.97058824]] \n",
      "\n",
      "The dot product of X and Y is: \n",
      " 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building vectors V and W:\n",
    "\n",
    "V = np.array([[9],[5],[0]])\n",
    "W = np.array([[3],[0],[5]])\n",
    "\n",
    "X = (lag.DotProduct(V, W)/lag.DotProduct(W, W))*W\n",
    "Y = V - X\n",
    "\n",
    "print(\"X: \\n\", X, '\\n')\n",
    "print(\"Y: \\n\", Y, '\\n')\n",
    "\n",
    "# Verifying if X and Y are orthogonal to each other.\n",
    "\n",
    "print(\"The dot product of X and Y is: \\n\", np.round(lag.DotProduct(X, Y), 8), '\\n' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1fb84a",
   "metadata": {},
   "source": [
    "**Exercise 9:** Let $U$ be a vector space spanned by the columns of $A$. Find an orthonormal basis for $U$ to generate an orthogonal matrix $Q$. Verify that $Q^TQ = I$ where $I$ is the identity matrix.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A = \\left[ \\begin{array}{r} 1 & 2 & -1\\\\ 0 & 2 & 1 \\\\  1 & 1 & 2 \\end{array}\\right]  \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b4edcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_reduced: \n",
      " [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the matrix A\n",
    "\n",
    "A = np.array([[1,2,-1],[0,2,1],[1,1,2]])\n",
    "A_red = lag.FullRowReduction(A)\n",
    "\n",
    "print(\"A_reduced: \\n\", A_red, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622116f8",
   "metadata": {},
   "source": [
    "We can see from the above code cell that there is a pivot in each column of $A$. Therefore, the column vectors of $A$ are linearly independent. As $U$ is spanned by the columns of $A$ and the columns of $A$ are linearly independent, we can say that the columns of $A$ are a basis for the vector space $U$.\n",
    "\n",
    "Let \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "x_1 = \\left[ \\begin{array}{r} 1\\\\ 0 \\\\ 1 \\end{array}\\right] \\hspace{1cm}\n",
    "x_2 = \\left[ \\begin{array}{r} 2 \\\\ 2 \\\\ 1 \\end{array}\\right] \\hspace{1cm}\n",
    "x_3 = \\left[ \\begin{array}{r} -1 \\\\ 1 \\\\ 2 \\end{array}\\right] \\hspace{1cm}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "Then, $U = \\texttt{Span}\\{x_1,x_2,x_3\\}$. Now, we can perform **Gram-Schimdt** orthogonalization on the bases vectors $x_1$, $x_2$, and $x_3$ to get the orthonormal vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ace1968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U_1: \n",
      " [[0.70710678]\n",
      " [0.        ]\n",
      " [0.70710678]] \n",
      "\n",
      "U_2: \n",
      " [[ 0.23570226]\n",
      " [ 0.94280904]\n",
      " [-0.23570226]] \n",
      "\n",
      "U_3: \n",
      " [[-0.66666667]\n",
      " [ 0.33333333]\n",
      " [ 0.66666667]] \n",
      "\n",
      "Q: \n",
      " [[ 0.70710678  0.23570226 -0.66666667]\n",
      " [ 0.          0.94280904  0.33333333]\n",
      " [ 0.70710678 -0.23570226  0.66666667]] \n",
      "\n",
      "Q_T@Q: \n",
      " [[ 1. -0. -0.]\n",
      " [-0.  1. -0.]\n",
      " [-0. -0.  1.]] \n",
      "\n",
      "I: \n",
      " [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## building the vectors X_1, X_2, X_3:\n",
    "\n",
    "X_1 = np.array([[1],[0],[1]])\n",
    "X_2 = np.array([[2],[2],[1]])\n",
    "X_3 = np.array([[-1],[1],[2]])\n",
    "\n",
    "## Let the orthogonal vectors be W_1, W_2, W_3:\n",
    "\n",
    "W_1 = X_1\n",
    "W_2 = X_2 - (lag.DotProduct(X_2, W_1)/lag.DotProduct(W_1, W_1))*W_1\n",
    "W_3 = X_3 - (lag.DotProduct(X_3, W_1)/lag.DotProduct(W_1, W_1))*W_1 - (lag.DotProduct(X_3, W_2)/lag.DotProduct(W_2, W_2))*W_2\n",
    "\n",
    "## Let the orthonormal vectors be U_1, U_2, U_3\n",
    "\n",
    "U_1 = W_1/math.sqrt(lag.DotProduct(W_1, W_1))\n",
    "U_2 = W_2/math.sqrt(lag.DotProduct(W_2, W_2))\n",
    "U_3 = W_3/math.sqrt(lag.DotProduct(W_3, W_3))\n",
    "\n",
    "\n",
    "print(\"U_1: \\n\", U_1, '\\n')\n",
    "print(\"U_2: \\n\", U_2, '\\n')\n",
    "print(\"U_3: \\n\", U_3, '\\n')\n",
    "\n",
    "## Stacking the orthonormal vectors in a matrix to get the orthogonal matrix Q:\n",
    "\n",
    "Q = np.hstack([U_1,U_2, U_3])\n",
    "print(\"Q: \\n\", Q, '\\n')\n",
    "\n",
    "\n",
    "## Verification:\n",
    "Q_T = np.transpose(Q)\n",
    "I = np.eye(3)\n",
    "\n",
    "\n",
    "print(\"Q_T@Q: \\n\", np.round(Q_T@Q, 8), '\\n')\n",
    "print(\"I: \\n\", I, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3d0adf",
   "metadata": {},
   "source": [
    "In the above code cell, we used **Gram-Schimdt** Orthogonalization to generate a set of orthonormal bases i.e $\\{U_1,U_2,U_3\\}$. Then, we can generate a matrix $Q$ which contains the orthonormal vectors as its columns. We have also verified that $Q^TQ = I$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924e7072",
   "metadata": {},
   "source": [
    "**Exercise 10:** Consider two vectors $X$ and $Y$. Given that $Z$ is the projection of $X$ in the direction of $Y$ and $X \\cdot Y = 6$, find $Y$.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X = \\left[ \\begin{array}{r} 2\\\\ 1 \\\\ 1 \\end{array}\\right] \\hspace{1cm}\n",
    "Z = \\left[ \\begin{array}{r} 1 \\\\ 1 \\\\ 0 \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8286d7",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "We have been given that the vector $Z$ is in the direction of vector $Y$. Therefore, the angle between the vector $X$ and the vector $Z$ is same as the angle between the vectors $X$ and $Y$. \n",
    "\n",
    "The angle between the vectors $X$ and $Z$ is as follows:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\cos{\\theta} = \\frac{X\\cdot Z}{||X||||Z||} = \\frac{3}{\\sqrt{2} \\sqrt{6}} = \\frac{\\sqrt{3}}{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Hence, $\\theta = 30^{\\circ}$ and this is also the angle between vectors $X$ and $Y$.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\cos{30^{\\circ}} = \\frac{X\\cdot Y}{||X||||Y||} = \\frac{6}{\\sqrt{6}||Y||} = \\frac{\\sqrt{3}}{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "From here, we can get $||Y||$ as follows:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "||Y|| = \\frac{2\\sqrt{6}}{\\sqrt{3}} = 2\\sqrt{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "Now, let us find  unit vector in the direction of $Y$. Unit vector in the direction of $Z$ is also the unit vector in the direction of $Y$.\n",
    "\n",
    "$\\hat{Y} =  \\frac{Z}{||Z||}$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{Y} = \\left[ \\begin{array}{r} \\frac{1}{\\sqrt{2}}\\\\ \\frac{1}{\\sqrt{2}} \\\\ 0 \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Therefore, the vector $Y$ is as follows:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Y = \\hat{Y}||Y|| = 2\\sqrt{2}\\left[ \\begin{array}{r} \\frac{1}{\\sqrt{2}}\\\\ \\frac{1}{\\sqrt{2}} \\\\ 0 \\end{array}\\right] =  \n",
    "\\left[ \\begin{array}{r} 2 \\\\ 2 \\\\ 0 \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b278af",
   "metadata": {},
   "source": [
    "### QR Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb6a2d",
   "metadata": {},
   "source": [
    "**Exercise 1:** \n",
    "\n",
    "($a$) Carry out the Gram-Schmidt algorithm on the following set of vectors to produce an orthonormal set $\\{U_1, U_2, U_3\\}$.  **Do not** use the $\\texttt{QRFactorization}$ function from this section or the SciPy $\\texttt{qr}$ function.  \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "V_1 = \\left[ \\begin{array}{r} 0 \\\\ 2 \\\\ 0 \\\\ 1 \\end{array}\\right] \\hspace{0.7cm} \n",
    "V_2 = \\left[ \\begin{array}{r} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{array}\\right] \\hspace{0.7cm}\n",
    "V_3 = \\left[ \\begin{array}{r} 2 \\\\ 2 \\\\ 0 \\\\ 1 \\end{array}\\right] \\hspace{0.7cm}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39b0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9fb485",
   "metadata": {},
   "source": [
    "($b$) Check your results by verifying that $\\{U_1, U_2, U_3\\}$ is an orthonormal set and that the span of $\\{U_1, U_2, U_3\\}$ equals the span of $\\{V_1, V_2, V_3\\}$.  (Reread [Linear_Combinations](Linear_Combinations.ipynb) if you are unsure how to verify the two spans are equal.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59243779",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea6d83",
   "metadata": {},
   "source": [
    "($c$) Check your results against those obtained using the $\\texttt{QRFactorization}$ function from this section or the $\\texttt{qr}$ function from SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd831d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ae3da8",
   "metadata": {},
   "source": [
    "**Exercise 2:** \n",
    "\n",
    "($a$) Predict what will happen if we attempt to find the QR factorization of matrix with *linearly dependent* columns.\n",
    "\n",
    "($b$) Try to compute the QR factorization on the following matrix with *linearly dependent* columns.  Try both the $\\texttt{QRFactorization}$ function from this section or the $\\texttt{qr}$ function from SciPy.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "B = \\left[ \\begin{array}{rrr} \n",
    "1 & 3 & -1  \\\\ \n",
    "0 & -1 & 1  \\\\ \n",
    "2 & 2 & 2  \\\\\n",
    "1 & 1 & 1  \\\\\n",
    "1 & 0 & 2  \\\\\n",
    "\\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadb74be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edfb536",
   "metadata": {},
   "source": [
    "**Exercise 3:** If possible, find the $QR$ factorization of the matrix $A$. Try to find the matrices $Q$ and $R$ without using the $\\texttt{QRFactorization}$ function from this section, then check your result by verifying that $QR=A$. \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A = \\left[ \\begin{array}{rrr} \n",
    "1 & 3 & 0 & 2  \\\\ \n",
    "0 & 1 & 2 & 1 \\\\ \n",
    "2 & 1 & 2 & 1 \\\\\n",
    "1 & 0 & 1 & 3 \\\\\n",
    "\\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3481ab25",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "We can find the $QR$ factorization of $A$ if the columns of $A$ are linearly independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "918fedda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_reduced:  \n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the matrix A\n",
    "\n",
    "A = np.array([[1,3,0,2],[0,1,2,1],[2,1,2,1],[1,0,1,3]])\n",
    "A_reduced = lag.FullRowReduction(A)\n",
    "\n",
    "print(\"A_reduced:  \\n\", A_reduced, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2edb4d",
   "metadata": {},
   "source": [
    "We see that there is a pivot in every column of the matrix $A$, which means the columns are linearly independent and we can find the $QR$ factorization.\n",
    "\n",
    "In order to find the orthogonal matrix $Q$, we perform the **Gram-Schimdt** orthogonalization on the columns of $A$.\n",
    "\n",
    "So, let\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "V_1 = \\left[ \\begin{array}{r} 1 \\\\ 0 \\\\ 2 \\\\ 1 \\end{array}\\right] \\hspace{0.7cm} \n",
    "V_2 = \\left[ \\begin{array}{r} 3 \\\\ 1 \\\\ 1 \\\\ 0 \\end{array}\\right] \\hspace{0.7cm}\n",
    "V_3 = \\left[ \\begin{array}{r} 0 \\\\ 2 \\\\ 2 \\\\ 1 \\end{array}\\right] \\hspace{0.7cm}\n",
    "V_4 = \\left[ \\begin{array}{r} 2 \\\\ 1 \\\\ 1 \\\\ 3 \\end{array}\\right] \\hspace{0.7cm}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e093ff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U_1: \n",
      " [[0.40824829]\n",
      " [0.        ]\n",
      " [0.81649658]\n",
      " [0.40824829]] \n",
      "\n",
      "U_2: \n",
      " [[ 0.82884973]\n",
      " [ 0.38254603]\n",
      " [-0.25503069]\n",
      " [-0.31878836]] \n",
      "\n",
      "U_3: \n",
      " [[-0.35516115]\n",
      " [ 0.92119924]\n",
      " [ 0.14428422]\n",
      " [ 0.06659272]] \n",
      "\n",
      "U_4: \n",
      " [[ 0.14213381]\n",
      " [ 0.07106691]\n",
      " [-0.49746834]\n",
      " [ 0.85280287]] \n",
      "\n",
      "Q: \n",
      " [[ 0.40824829  0.82884973 -0.35516115  0.14213381]\n",
      " [ 0.          0.38254603  0.92119924  0.07106691]\n",
      " [ 0.81649658 -0.25503069  0.14428422 -0.49746834]\n",
      " [ 0.40824829 -0.31878836  0.06659272  0.85280287]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Building vectors V_1, V_2, V_3, V_4:\n",
    "\n",
    "V_1 = np.array([[1],[0],[2],[1]])\n",
    "V_2 = np.array([[3],[1],[1],[0]])\n",
    "V_3 = np.array([[0],[2],[2],[1]])\n",
    "V_4 = np.array([[2],[1],[1],[3]])\n",
    "\n",
    "\n",
    "## Building the orthogonal vectors W_1, W_2,W_3, W_4:\n",
    "\n",
    "W_1 = V_1\n",
    "W_2 = V_2 - (lag.DotProduct(V_2, W_1)/lag.DotProduct(W_1,W_1))*W_1\n",
    "W_3 = V_3 - (lag.DotProduct(V_3, W_1)/lag.DotProduct(W_1,W_1))*W_1 - (lag.DotProduct(V_3, W_2)/lag.DotProduct(W_2, W_2))*W_2\n",
    "W_4 = V_4 - (lag.DotProduct(V_4, W_1)/lag.DotProduct(W_1,W_1))*W_1 - (lag.DotProduct(V_4, W_2)/lag.DotProduct(W_2, W_2))*W_2 - (lag.DotProduct(V_4, W_3)/lag.DotProduct(W_3, W_3))*W_3\n",
    "\n",
    "\n",
    "## Building the orthonormal vectors U_1, U_2, U_3, U_4:\n",
    "\n",
    "U_1 = W_1/math.sqrt(lag.DotProduct(W_1,W_1))\n",
    "U_2 = W_2/math.sqrt(lag.DotProduct(W_2,W_2))\n",
    "U_3 = W_3/math.sqrt(lag.DotProduct(W_3,W_3))\n",
    "U_4 = W_4/math.sqrt(lag.DotProduct(W_4,W_4))\n",
    "\n",
    "\n",
    "print(\"U_1: \\n\", U_1, '\\n')\n",
    "print(\"U_2: \\n\", U_2, '\\n')\n",
    "print(\"U_3: \\n\", U_3, '\\n')\n",
    "print(\"U_4: \\n\", U_4, '\\n')\n",
    "\n",
    "Q = np.hstack([U_1,U_2,U_3,U_4])\n",
    "\n",
    "print(\"Q: \\n\", Q, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fc6304",
   "metadata": {},
   "source": [
    "The vectors that result from the orthogonalization form the matrix $Q$.  Now, we compute $R$ and verify that $QR=A$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9038ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: \n",
      " [[ 2.44949  2.04124  2.04124  2.85774]\n",
      " [-0.       2.61406 -0.06376  0.82885]\n",
      " [-0.      -0.       2.19756  0.55494]\n",
      " [ 0.       0.       0.       2.41627]] \n",
      "\n",
      "A: \n",
      " [[1 3 0 2]\n",
      " [0 1 2 1]\n",
      " [2 1 2 1]\n",
      " [1 0 1 3]] \n",
      "\n",
      "QR: \n",
      " [[ 1.  3. -0.  2.]\n",
      " [ 0.  1.  2.  1.]\n",
      " [ 2.  1.  2.  1.]\n",
      " [ 1.  0.  1.  3.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Q_trans = np.transpose(Q)\n",
    "R = np.round(Q_trans@A,5)\n",
    "\n",
    "print(\"R: \\n\", R, '\\n')\n",
    "\n",
    "## Verifying that A = QR\n",
    "\n",
    "print(\"A: \\n\", A, '\\n')\n",
    "print(\"QR: \\n\", np.round(Q@R,5), '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb2e5c",
   "metadata": {},
   "source": [
    "**Exercise 4:** Are all matrices which have $QR$ factorization invertible? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c852888",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "No, not all matrices which have $QR$ factorization are invertible. Only square matrices can be invertible, but non-square matrices may have $QR$ factorizations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f8f7f8",
   "metadata": {},
   "source": [
    "**Exercise 5:** Use the $QR$ factorization of $A$ to solve the given linear system $AX = B$, and verify the solution.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "AX = \\left[ \\begin{array}{rrrr} \n",
    "1 & 2 & 3  \\\\ \n",
    "0 & 3 & 2  \\\\ \n",
    "1 & 1 & 4  \\\\\n",
    "\\end{array}\\right]\n",
    "\\quad\\quad\n",
    "X = \n",
    "\\left[ \\begin{array}{r} 1 \\\\ 1 \\\\ 1 \\\\  \\end{array} \\right]\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44157985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      " [[-3.]\n",
      " [-1.]\n",
      " [ 2.]] \n",
      "\n",
      "AX: \n",
      " [[1.]\n",
      " [1.]\n",
      " [4.]] \n",
      "\n",
      "B: \n",
      " [[1]\n",
      " [1]\n",
      " [4]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the matrices A and B:\n",
    "\n",
    "A = np.array([[1,2,3],[0,3,2],[1,1,4]])\n",
    "B = np.array([[1],[1],[4]])\n",
    "\n",
    "Q,R = lag.QRFactorization(A)\n",
    "\n",
    "C = Q.transpose()@B\n",
    "\n",
    "X = lag.BackSubstitution(R, C)\n",
    "\n",
    "print(\"X: \\n\", X, '\\n')\n",
    "\n",
    "\n",
    "## Verifying that AX = B\n",
    "\n",
    "print(\"AX: \\n\", A@X, '\\n')\n",
    "print(\"B: \\n\", B, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dbbc4d",
   "metadata": {},
   "source": [
    "The computation verifies $AX = B$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b2f31d",
   "metadata": {},
   "source": [
    "**Exercise 6:** $A$ and $B$ are two $n \\times n$ matrices. \n",
    "\n",
    "  ($a$) Given that the product $BA$ has $QR$ factorization, prove that the matrix $A$ also has a $QR$ factorization. \n",
    "  \n",
    "   ($b$) Can you think of matrices $A$ and $B$ such that $B$ has linearly dependent columns  but the product $BA$ has $QR$ factorization? Explain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20d5ccc",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "$(a)$ It has been given that the product $BA$ has a $QR$ factorization, this means that the columns of the matrix $BA$ are linearly independent. If the columns of an $n \\times n$ matrix $P$ are linearly independent, it means that the solution to the system $PX = R$ will be unique.\n",
    "\n",
    "Therefore, if the columns of matrix $BA$ are linearly independent, this implies that the homogenous system $BAX = 0$ must have a trivial solution i.e $X = 0$.\n",
    "\n",
    "\n",
    "Now, let us consider the homogenous system $AX = 0$. If we multiply both the sides of this equation by $B$, it gives:\n",
    "\n",
    "$AX = 0$\n",
    "\n",
    "$ B(AX) = B(0)$\n",
    "\n",
    "$ (BA)X = 0$\n",
    "\n",
    "This means $X = 0$ since $BA(X) = 0$  has a trivial solution only.\n",
    "\n",
    "So, we started off by saying that $AX = 0$ and we got $X = 0$. This means that the system $AX = 0$ has only the trivial solution. This means that the columns of $A$ are also linearly independent. Therefore, $A$ also has a $QR$ factorization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed60912",
   "metadata": {},
   "source": [
    "$(b)$ Let us consider a $ 2 \\times 3$ matrix $B$ and its transpose.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "B = \\left[ \\begin{array}{rr} 1 && 2 && 1 \\\\ 2 && 3 && 0   \\end{array}\\right] \\hspace{0.7cm} \n",
    "\\quad\\quad\n",
    "B^T = \\left[ \\begin{array}{rr} 1 && 2 \\\\ 2 && 3 \\\\ 1 && 0  \\end{array}\\right] \\hspace{0.7cm} \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "Now, let us consider the product $BB^T$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a48c5f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product of B and B_transpose is:  \n",
      " [[ 6  8]\n",
      " [ 8 13]] \n",
      "\n",
      "U: \n",
      " [[1. 0.]\n",
      " [0. 1.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the matrices B and B_transpose\n",
    "\n",
    "B = np.array([[1,2,1],[2,3,0]])\n",
    "B_transpose = np.transpose(B)\n",
    "\n",
    "print(\"The product of B and B_transpose is:  \\n\", B@B_transpose, '\\n')\n",
    "\n",
    "U = lag.FullRowReduction(B@B_transpose)\n",
    "\n",
    "print(\"U: \\n\", U, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb32597",
   "metadata": {},
   "source": [
    "We see that though the matrix $B$ has linearly dependent columns, the matrix $BB^T$ has linearly independent columns ($BB^T$ has a pivot in each column).  Hence, we can say that the matrix $BB^T$ has a $QR$ factorization.\n",
    "\n",
    "Therefore, if we consider that the matrix $A = B^T$, then $BA$ has a $QR$ factorization even though $B$ does not have a $QR$ factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d50f5",
   "metadata": {},
   "source": [
    "**Exercise 7:** If $A$ is an $n \\times n$ invertible matrix, explain why $A^TA$ is also invertible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d5b7d6",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "If we assume that the matrix $A$ is invertible, then it has a pivot in each column.  This means that the columns of $A$ are linearly independent and that $A$ has a $QR$ factorization.\n",
    "\n",
    "So, $ A^TA = (QR)^T(QR)$ = $ R^TQ^TQR = R^T(Q^TQ)R = R^TR $.\n",
    "\n",
    "Since $R$ is an upper-triangular matrix with non-zero enteries on the diagonal we can reduce it to the identity matrix $I$ by performing row operations.  This means that $R$ is invertible. The matrix $R^T$ is lower triangular with non-zero entries on the diagonal and is invertible for the same reason.  Since $A^TA$ is the product of two invertible matrices, it must also be invertible.  (*See exercises in [Inverse Matrices](Inverse_Matrices.ipynb).)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cfd633",
   "metadata": {},
   "source": [
    "### Orthogonal Subspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d812d7e",
   "metadata": {},
   "source": [
    "**Exercise 1:** Let $B$ be the following $4\\times 3$ matrix.  Find bases for $\\mathcal{C}(B^T)$ and $\\mathcal{N}(B)$, the row space and null space of $B$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "B = \\left[ \\begin{array}{rrr} 4 & -3 & -2  \\\\ 2 & 0 & 2 \\\\ 0 & 1 & 2 \\\\ 1 & 1 & 1 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4df91122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  2  0  1]\n",
      " [-3  0  1  1]\n",
      " [-2  2  2  1]] \n",
      "\n",
      "[[ 1.          0.         -0.33333333  0.        ]\n",
      " [ 0.          1.          0.66666667  0.        ]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "B = np.array([[4,-3,-2],[2,0,2],[0,1,2],[1,1,1]])\n",
    "B_transpose = B.transpose()\n",
    "B_transpose_reduced = lag.FullRowReduction(B_transpose)\n",
    "print(B_transpose,'\\n')\n",
    "print(B_transpose_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b2e1e",
   "metadata": {},
   "source": [
    "There are pivots in the first, second, and fourth column of $B^T$ so the following set of vectors is a basis for $\\mathcal{C}(B^T)$.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\left\\{ \\left[\\begin{array}{r} 4 \\\\ -3 \\\\ -2 \\end{array}\\right]\\hspace{0.2cm}, \\hspace{0.2cm} \\left[\\begin{array}{r} 2 \\\\ 0 \\\\ 2 \\end{array}\\right]\\hspace{0.2cm}, \\hspace{0.2cm} \\left[\\begin{array}{r} 1 \\\\ 1 \\\\ 1 \\end{array}\\right] \\right\\}\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19bbcbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 -3 -2]\n",
      " [ 2  0  2]\n",
      " [ 0  1  2]\n",
      " [ 1  1  1]] \n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "B_reduced = lag.FullRowReduction(B)\n",
    "print(B,'\\n')\n",
    "print(B_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48db618",
   "metadata": {},
   "source": [
    "Since every column has a pivot, the columns of $B$ are linearly independent and therefore the only solution to $BX = 0$ is $X = 0$. Thus the null space of $B$ contains only the zero vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0525a",
   "metadata": {},
   "source": [
    "**Exercise 2:** Using the matrix $B$ and the bases from the previous exercise, determine vectors $P$ and $E$ such that $P$ is in $\\mathcal{C}(B^T)$, $E$ is in $\\mathcal{N}(B)$, and $P+E = X$, where $X$ is the following vector.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X = \\left[ \\begin{array}{r}1 \\\\ 0 \\\\ 1 \\\\ 1 \\end{array}\\right]\\hspace{0.7cm}  \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6448e386",
   "metadata": {},
   "source": [
    "**Exercise 3:** Let $A$ be the matrix in **Example 3**.  Find bases for $\\mathcal{C}(A)$ and $\\mathcal{N}(A^T)$, the column space and left null space of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac831089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 2 0]\n",
      " [3 0 1 1]\n",
      " [1 1 1 0]] \n",
      "\n",
      "[[ 1.   0.   0.   0.5]\n",
      " [ 0.   1.   0.   0. ]\n",
      " [ 0.   0.   1.  -0.5]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2, 1, 2, 0],[3, 0, 1, 1],[1, 1, 1, 0]])\n",
    "A_reduced = lag.FullRowReduction(A)\n",
    "print(A,'\\n')\n",
    "print(A_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5eb5ba",
   "metadata": {},
   "source": [
    "There are pivots in the first three columns of $A$ so the following set of vectors is a basis for $\\mathcal{C}(A)$.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\left\\{ \\left[\\begin{array}{r} 2 \\\\ 3 \\\\ 1 \\end{array}\\right]\\hspace{0.2cm}, \\hspace{0.2cm} \\left[\\begin{array}{r} 1 \\\\ 0 \\\\ 1 \\end{array}\\right]\\hspace{0.2cm}, \\hspace{0.2cm} \\left[\\begin{array}{r} 2 \\\\ 1 \\\\ 1 \\end{array}\\right] \\right\\}\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a8a66e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 1]\n",
      " [1 0 1]\n",
      " [2 1 1]\n",
      " [0 1 0]] \n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "A_transpose = A.transpose()\n",
    "A_transpose_reduced = lag.FullRowReduction(A_transpose)\n",
    "print(A_transpose,'\\n')\n",
    "print(A_transpose_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5e719a",
   "metadata": {},
   "source": [
    "Since every column has a pivot, the columns of $A^T$ are linearly independent and therefore the only solution to $A^TX = 0$ is $X = 0$. Thus the left null space of $A$ contains only the zero vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a52ff11",
   "metadata": {},
   "source": [
    "**Exercise 4:** Let $\\mathcal{U}$ be the subspace of $\\mathbb{R}^4$ spanned by $\\{U_1,U_2\\}$. Find a basis for the orthogonal complement $U^{\\perp}$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "U_1 = \\left[ \\begin{array}{r} 1 \\\\ 0 \\\\ 2 \\\\ 2 \\end{array}\\right] \\hspace{0.7cm} \n",
    "U_2 = \\left[ \\begin{array}{r} -2 \\\\ 1 \\\\ 0 \\\\ -1 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e397f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0bedf",
   "metadata": {},
   "source": [
    "**Exercise 5:** Let $\\mathcal{W}$ be a subspace of $\\mathbb{R}^5$ with basis $\\{W_1, W_2, W_3\\}$.  Find a basis for the orthogonal complement $\\mathcal{W}^{\\perp}$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "W_1 = \\left[ \\begin{array}{r} 1 \\\\ 1 \\\\ 0 \\\\ 1 \\\\ 1 \\end{array}\\right]\\hspace{0.7cm}  \n",
    "W_2 = \\left[ \\begin{array}{r} 3 \\\\ 2 \\\\ 0 \\\\ 1 \\\\ 1 \\end{array}\\right]\\hspace{0.7cm} \n",
    "W_3 = \\left[ \\begin{array}{r} 0 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 2 \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad730ea",
   "metadata": {},
   "source": [
    "If we take the vectors $W_1, W_2,$ and $W_3$ as the columns of the following matrix $W$, then the column space of $W$ is precisely $\\mathcal{W}$. But we know that the orthogonal complement of the column space of matrix is equivalent to the left null space of that matrix, so we look for a basis of the left null space of $W$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "W = \\left[ \\begin{array}{rrr} 1 & 3 & 0  \\\\ 1 & 2 & 1 \\\\ 0 & 0 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 2 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "273bb9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 1]\n",
      " [3 2 0 1 1]\n",
      " [0 1 1 1 2]] \n",
      "\n",
      "[[ 1.  0.  0. -1. -1.]\n",
      " [ 0.  1.  0.  2.  2.]\n",
      " [ 0.  0.  1. -1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "W = np.array([[1,3,0],[1,2,1],[0,0,1],[1,1,1],[1,1,2]])\n",
    "W_transpose = W.transpose()\n",
    "W_transpose_reduced = lag.FullRowReduction(W_transpose)\n",
    "print(W_transpose,'\\n')\n",
    "print(W_transpose_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a09e13",
   "metadata": {},
   "source": [
    "There exists pivots in the first three columns only, so $x_4$ and $x_5$ are free variables. If we parametrize $x_4 = r$  and $x_5 = s$ then $x_1 = r + s$ and $x_2 = -2r -2s$ and $x_3 = r$. Then we can write the components of a general solution vector $X$ to the equation $W^TX = 0$ in terms of these parameters.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X = \\left[ \\begin{array}{r} x_1 \\\\ x_ 2 \\\\ x_ 3 \\\\ x_4 \\\\ x_5 \\end{array}\\right] =  \n",
    "r\\left[ \\begin{array}{r} 1 \\\\ -2 \\\\  1 \\\\ 1 \\\\ 0\\end{array}\\right] + s\\left[ \\begin{array}{r} 1 \\\\ -2 \\\\  0 \\\\ 0 \\\\ 1\\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Therefore the following set of vectors forms a basis for $\\mathcal{N}(W^T)$ or $\\mathcal{W}^{\\perp}$\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\left\\{ \\left[\\begin{array}{r} 1 \\\\ -2 \\\\ 1 \\\\ 1 \\\\ 0 \\end{array}\\right]\\hspace{0.2cm}, \\hspace{0.2cm} \\left[\\begin{array}{r} 1 \\\\ -2 \\\\ 0 \\\\ 0 \\\\ 1 \\end{array}\\right] \\right\\}\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cde6e9",
   "metadata": {},
   "source": [
    "**Exercise 6:** Let $U$ and $W$ be the subspaces of $\\mathbb{R}^4$ where $U$ is the span of $\\{V_1,V_2\\}$ and $W$ is the span of $\\{V_3,V_4\\}$. Determine whether $U$ and $W$ are orthogonal complements of each other. \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "V_1 = \\left[ \\begin{array}{r} 1 \\\\ 0 \\\\ 2 \\\\ 1 \\end{array}\\right]\\hspace{0.7cm}  \n",
    "V_2 = \\left[ \\begin{array}{r} 1 \\\\ -1 \\\\ 2 \\\\ 0 \\end{array}\\right]\\hspace{0.7cm} \n",
    "V_3 = \\left[ \\begin{array}{r} -1 \\\\ 1 \\\\ 1 \\\\ -1 \\end{array}\\right]\\hspace{0.7cm}\n",
    "V_4 = \\left[ \\begin{array}{r} -2 \\\\ 0 \\\\ 1 \\\\ 0 \\end{array}\\right]\\hspace{0.7cm}\n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd711509",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "First we check if the subspaces $U$ and $W$ are orthogonal to each other. Consider that the matrix $A$ contains vectors $V_1$, $V_2$ as its columns and the matrix $B$ contains $V_3$, $V_4$ as its columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530d8b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_trans@B: \n",
      " [[0 0]\n",
      " [0 0]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the matrices A and B:\n",
    "\n",
    "A = np.array([[1,1],[0,-1],[2,2],[1,0]])\n",
    "B = np.array([[-1,-2],[1,0],[1,1],[-1,0]])\n",
    "\n",
    "A_trans = np.transpose(A)\n",
    "print(\"A_trans@B: \\n\", A_trans@B, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deb47f0",
   "metadata": {},
   "source": [
    "The subspaces $U$ and $W$ are orthogonal to each other since $A^TB$ is a zero matrix. In order to see if $U$ and $W$ are orthogonal complements of each other, we need to find out if $\\{V_1,V_2,V_3,V_4\\}$ forms a basis for $\\mathbb{R}^4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc444090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: \n",
      " [[ 1  1 -1 -2]\n",
      " [ 0 -1  1  0]\n",
      " [ 2  2  1  1]\n",
      " [ 1  0 -1  0]] \n",
      "\n",
      "C_reduced:  \n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Let C be the matrix with V_1, V_2, V_3, V_4 as its columns:\n",
    "\n",
    "C = np.array([[1,1,-1,-2],[0,-1,1,0],[2,2,1,1],[1,0,-1,0]])\n",
    "C_reduced = lag.FullRowReduction(C)\n",
    "\n",
    "print(\"C: \\n\", C, '\\n')\n",
    "print(\"C_reduced:  \\n\", C_reduced, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e38b0ec",
   "metadata": {},
   "source": [
    "Since there is a pivot in each row and column of the matrix $C$ which contains the vectors $V_1$, $V_2$, $V_3$ and $V_4$ as its columns, this means that $\\{V_1,V_2,V_3,V_4\\}$ is a basis for $\\mathbb{R}^4$. Therefore, we can say that the subspaces $U$ and $W$ are orthogonal complements of each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431aca01",
   "metadata": {},
   "source": [
    "**Exercise 7:** Find vectors $P$ and $E$ such that $P$ is in the column space of the matrix $A$, $E$ is orthogonal to $P$ and $B = P + E$. Verify your answer.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A = \\left[ \\begin{array}{rr} 1 & 2\\\\ 2 & 1\\\\ 2 & -2\\end{array}\\right] \\hspace{1cm}\n",
    "B = \\left[ \\begin{array}{rr} 1 \\\\ 1 \\\\ 1 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2d8ea2",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "We first find a basis for $\\mathcal{C}(A)$, the column space of $A$. \n",
    "As there is a pivot in each column of the matrix $A$, the two columns of $A$ form a basis for $\\mathcal{C}(A)$.\n",
    "Therefore, we can say that a basis for $C(A)$ is $\\{X_1,X_2\\}$, where $X_1$ and $X_2$ are as follows:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X_1 = \\left[ \\begin{array}{r} 1 \\\\ 2 \\\\ 2  \\end{array}\\right]\\hspace{0.7cm}  \n",
    "X_2 = \\left[ \\begin{array}{r} 2 \\\\ 1 \\\\ -2 \\end{array}\\right]\\hspace{0.7cm} \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "Now $P$ is the orthogonal projection of $B$ onto $\\mathcal{C}(A)$. Once we calculate $P$, we can find $E$ by subtracting the vector $P$ from the vector $B$.  If $\\{U_1,U_2\\}$ is an orthonormal basis for $\\mathcal{C}(A)$, then\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "P =  \\langle U_1,B\\rangle U_1 + \\langle U_2,B\\rangle U_2 \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "To calculate $P$, we therefore need to find the orthonormal basis $\\{U_1,U_2\\}$.  Since $X_1\\cdot X_2 = 0$, the vectors $X_1$ and $X_2$ are orthogonal.  We need to scale $X_1$ and $X_2$ to unit length to produce the orthonormal basis $\\{U_1, U_2\\}$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "U_1 = \\frac{1}{3}\\left[ \\begin{array}{r} 1 \\\\ 2 \\\\ 2  \\end{array}\\right]\\hspace{0.7cm} \n",
    "U_2 = \\frac{1}{3} \\left[ \\begin{array}{r} 2 \\\\ 1 \\\\ -2 \\end{array}\\right]\\hspace{0.7cm} \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Now $B\\cdot U_1 = \\frac{5}{3}$ and $B\\cdot U_2 = \\frac{1}{3}$, so\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "P = \\frac{5}{(3)(3)}\\left[ \\begin{array}{r} 1 \\\\ 2 \\\\ 2  \\end{array}\\right]    + \n",
    "\\frac{1}{(3)(3)} \\left[ \\begin{array}{r} 2 \\\\ 1 \\\\ -2 \\end{array}\\right]  =  \\frac{1}{9}\\left[ \\begin{array}{r} 7 \\\\ 11 \\\\ 8  \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Then $E$ is the difference of $B$ and $P$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "E = B-P = \\left[ \\begin{array}{r} 1 \\\\ 1 \\\\ 1  \\end{array}\\right] -\n",
    " \\frac{1}{9} \\left[ \\begin{array}{r} 7 \\\\ 11 \\\\ 8 \\end{array}\\right]  = \\frac{1}{9}\\left[ \\begin{array}{r} 2 \\\\ -2 \\\\ 1  \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "If our answers are correct, then $P$ and $E$ must be orthogonal to each other. We can check this in the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8cc3bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product of P and E is: \n",
      " 0.0\n"
     ]
    }
   ],
   "source": [
    "P = np.array([[7/9],[11/9],[8/9]])\n",
    "E = np.array([[2/9],[-2/9],[1/9]])\n",
    "\n",
    "print(\"Dot product of P and E is: \\n\", lag.DotProduct(P,E))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02414ea",
   "metadata": {},
   "source": [
    "**Exercise 8:** Let $\\{X_1,X_2\\}$ be a basis for subspace $U$ of $\\mathbb{R}^3$ and $\\{X_3\\}$ be a basis for $W$. Find the values of $a$ and $b$ for which subspaces $U$ are $W$ are orthogonal complements of each other.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X_1 = \\left[ \\begin{array}{r} b \\\\ a \\\\ 2  \\end{array}\\right]\\hspace{0.7cm}  \n",
    "X_2 = \\left[ \\begin{array}{r} 2 \\\\ -3 \\\\ 3  \\end{array}\\right]\\hspace{0.7cm} \n",
    "X_3 = \\left[ \\begin{array}{r} 3 \\\\ b \\\\ a \\end{array}\\right]\\hspace{0.7cm}\n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e2c12",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "For subspaces $U$ and $W$ to be orthogonal to each other, we need $X_1\\cdot X_3 = 0$, $X_2\\cdot X_3 = 0$  This gives two equations\n",
    "\n",
    "$3b + ab + 2a = 0$\n",
    "\n",
    "$6 - 3b + 3a = 0$\n",
    "\n",
    "This system of equations is not linear, so we cannot use elimination to find a solution.  We solve the second equation for $b$ to get $ b = a + 2$, and substitute the result into the first equation\n",
    "\n",
    "$3(a + 2) + a(a-2) + 2a  = 0$\n",
    "\n",
    "This gives a quadratic equation for $a$.\n",
    "\n",
    "$ a^2 + 7a + 6 = 0$\n",
    "\n",
    "The roots of the equation are $ a = -1$ and  $a=-6$.\n",
    "\n",
    "When $a=-1$, $b=1$ and $X_1$, $X_2$ and $X_3$ are as follows:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X_1 = \\left[ \\begin{array}{r} 1 \\\\ -1 \\\\ 2  \\end{array}\\right]\\hspace{0.7cm}  \n",
    "X_2 = \\left[ \\begin{array}{r} 2 \\\\ -3 \\\\ 3  \\end{array}\\right]\\hspace{0.7cm} \n",
    "X_3 = \\left[ \\begin{array}{r} 3 \\\\ 1 \\\\ -1 \\end{array}\\right]\\hspace{0.7cm}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "When $a=-6$, $b=-4$ and $X_1$, $X_2$ and $X_3$ are as follows:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X_1 = \\left[ \\begin{array}{r} -4 \\\\ -6 \\\\ 2  \\end{array}\\right]\\hspace{0.7cm}  \n",
    "X_2 = \\left[ \\begin{array}{r} 2 \\\\ -3 \\\\ 3  \\end{array}\\right]\\hspace{0.7cm} \n",
    "X_3 = \\left[ \\begin{array}{r} 3 \\\\ -4 \\\\ -6 \\end{array}\\right]\\hspace{0.7cm}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "For each pair of $a$, $b$ values we need to check that $\\{X_1,X_2,X_3\\}$ is a basis for $\\mathbb{R}^3$ to determine whether $U$ and $W$ are orthogonal complements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1abf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_reduced: \n",
      " [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]] \n",
      "\n",
      "B_reduced: \n",
      " [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building matrix A with X_1, X_2, X_3 as its columns when a = -1, b = 1:\n",
    "\n",
    "A = np.array([[1,2,3],[-1,-3,1],[2,3,-1]])\n",
    "A_reduced = lag.FullRowReduction(A)\n",
    "\n",
    "print(\"A_reduced: \\n\", A_reduced, '\\n')\n",
    "\n",
    "\n",
    "## Building the matrix B with X_1, X_2, X_3 as its columns when a = -6, b = -4:\n",
    "\n",
    "B = np.array([[-4, 2, 3],[-6,-3,-4],[2,3,-6]])\n",
    "B_reduced = lag.FullRowReduction(B)\n",
    "\n",
    "print(\"B_reduced: \\n\", B_reduced, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16f37cb",
   "metadata": {},
   "source": [
    "Since there is a pivot in each row and column of the matrices $A$ and $B$, $\\{X_1,X_2,X_3\\}$ is a basis for $\\mathbb{R}^3$ in both cases.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5f57b4",
   "metadata": {},
   "source": [
    "**Exercise 9:** Let $U$ be a subspace of $\\mathbb{R}^4$ and it has $3$ vectors in its basis. Can you determine the number of vectors in the basis of $U^{\\perp}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce732b",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "The basis for $U$ and the basis for $U^{\\perp}$ should together be the basis for $\\mathbb{R}^4$.  This means that $ dim(U) + dim(U^{\\perp}) = dim(\\mathbb{R}^4)$.  Since $dim(\\mathbb{R}^4) = 4$, $ dim(U^{\\perp}) = 1$.  Therefore, any basis of $U^{\\perp}$ contains only one vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a24db8",
   "metadata": {},
   "source": [
    "**Exercise 10:** Let $U$ of $\\mathbb{R}^3$ spanned by $\\{X_1,X_2\\}$.  Decompose the vector $V$ in $\\mathbb{R}^3$ such that one component is in subspace $U$ and other component in $U^{\\perp}$.\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X_1 = \\left[ \\begin{array}{r} 1 \\\\ 0 \\\\ 1 \\end{array}\\right]\\hspace{0.7cm}  \n",
    "X_2 = \\left[ \\begin{array}{r} 2 \\\\ 2 \\\\ 3 \\end{array}\\right]\\hspace{0.7cm} \n",
    "V = \\left[ \\begin{array}{r} -1 \\\\ 0 \\\\ 8 \\end{array}\\right]\\hspace{0.7cm} \n",
    "\\end{equation}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc94068b",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "We would first start by finding a basis for $U^{\\perp}$. Let $\\{X_3\\}$ be a vector $U^{\\perp}$.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X_3 = \\left[ \\begin{array}{r} a \\\\ b \\\\ c  \\end{array}\\right]\\hspace{0.7cm}  \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Since $U^{\\perp}$ is the orthogonal complement of $U$, $X_1\\cdot X_3 = 0$ and $X_2\\cdot X_3 = 0$.\n",
    "\n",
    "\n",
    "$ a + c = 0$\n",
    "\n",
    "$ 2a + 2b + 3c = 0$\n",
    "\n",
    "In this system of equations, we observe that $c$ is a free variable, and let $c = t$ where $t$. We then find $ a = -t$ and $b = -t/2$.  Since we only need one specific vector to form a basis for $U^{\\perp}$, we let $t=2$ and\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X_3 = \\left[ \\begin{array}{r} -2 \\\\  -1 \\\\ 2  \\end{array}\\right]\\hspace{0.7cm}  \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Now $\\{X_1,X_2,X_3\\}$ is a basis for $\\mathbb{R}^3$ and $V$ is a linear combination of the basis vectors.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "V =\\left[ \\begin{array}{r} -1 \\\\ 0 \\\\ 8  \\end{array}\\right]= a\\left[ \\begin{array}{r} 1 \\\\ 0 \\\\ 1  \\end{array}\\right]  +  \n",
    " b \\left[ \\begin{array}{r} 2 \\\\ 2 \\\\ 3 \\end{array}\\right]  + \n",
    "  c \\left[ \\begin{array}{r} -2 \\\\ -1 \\\\ 2 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "We solve a system of equations to get the values of $a$, $b$, $c$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f8790e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      " [[1.]\n",
      " [1.]\n",
      " [2.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the matrix A with X_1,X_2, X_3 as its columns and B represents the vector V:\n",
    "\n",
    "A = np.array([[1,2,-2],[0,2,-1],[1,3,2]])\n",
    "B = np.array([[-1],[0],[8]])\n",
    "\n",
    "X = lag.SolveSystem(A, B)\n",
    "\n",
    "print(\"X: \\n\", X, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16e98d6",
   "metadata": {},
   "source": [
    "Therefore, \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "V = 1\\left[ \\begin{array}{r} 1 \\\\ 0 \\\\ 1  \\end{array}\\right]  +  \n",
    " 1 \\left[ \\begin{array}{r} 2 \\\\ 2 \\\\ 3 \\end{array}\\right]  + \n",
    "  2 \\left[ \\begin{array}{r} -2 \\\\ -1 \\\\ 2 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Let $ V = V_1 + V_2$ with $V_1$ in the subspace $U$ and $V_2$ in the orthogonal complement $U^{\\perp}$. \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "V_1 = 1\\left[ \\begin{array}{r} 1 \\\\ 0 \\\\ 1  \\end{array}\\right]  +  \n",
    " 1 \\left[ \\begin{array}{r} 2 \\\\ 2 \\\\ 3 \\end{array}\\right]  = \n",
    "  \\left[ \\begin{array}{r} 3 \\\\ 2 \\\\ 4 \\end{array}\\right] \\hspace{1cm}\n",
    "V_2 = 2 \\left[ \\begin{array}{r} -2 \\\\ -1 \\\\ 2 \\end{array}\\right] = \n",
    "\\left[ \\begin{array}{r} -4 \\\\ -2 \\\\ 4  \\end{array}\\right]  \n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967e2dcd",
   "metadata": {},
   "source": [
    "**Exercise 11:** \n",
    "\n",
    "($a$) Find a basis for each of the four of fundamental subspaces ($\\mathcal{C}(A)$, $\\mathcal{N}(A)$, $\\mathcal{R}(A)$, and $\\mathcal{N}(A^T)$) associated with $A$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A = \\left[ \\begin{array}{r} 1 & 1 & 0 & 2 & -1 \\\\ 1 & 0 & 1 & -1 & 0 \\\\ 3 & 1 & 2 & 0 & -1 \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24946328",
   "metadata": {},
   "source": [
    "**Solution:**  First we use $\\texttt{FullRowReduction}$ to reduce $A$ and $A^T$ into RREF forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce7c531c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  1. -1.  0.]\n",
      " [ 0.  1. -1.  3. -1.]\n",
      " [ 0.  0.  0.  0.  0.]] \n",
      "\n",
      "[[1. 0. 1.]\n",
      " [0. 1. 2.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,1,0,2,-1],[1,0,1,-1,0],[3,1,2,0,-1]])\n",
    "A_reduced = lag.FullRowReduction(A)\n",
    "A_transpose = A.transpose()\n",
    "A_transpose_reduced = lag.FullRowReduction(A_transpose)\n",
    "print(A_reduced,'\\n')\n",
    "print(A_transpose_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dee978",
   "metadata": {},
   "source": [
    "We know that the linearly independent columns of $A$ form a basis for the columns of $A$, and the pivot columns are precisely those vectors. Therefore the following is a basis for $\\mathcal{C}(A)$\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\left\\{ \\left[\\begin{array}{r} 1 \\\\ 1 \\\\ 3 \\end{array}\\right]\\hspace{0.2cm}, \\hspace{0.2cm} \\left[\\begin{array}{r} 1 \\\\ 0 \\\\ 1 \\end{array}\\right] \\right\\}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Similarily, the set of pivot columns of $A^T$ forms a basis for $\\mathcal{R}(A)$\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\left\\{ \\left[\\begin{array}{r} 1 \\\\ 1 \\\\ 0 \\\\ 2 \\\\ -1 \\end{array}\\right]\\hspace{0.2cm}, \\hspace{0.2cm} \\left[\\begin{array}{r} 1 \\\\ 0 \\\\ 1 \\\\ -1 \\\\ 0 \\end{array}\\right] \\right\\}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Recall that to find a basis for $\\mathcal{N}(A)$ we first find the solutions to $AX = 0$. We start by forming the appropriate augmented matrix and then finding its RREF form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "517ad1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  1. -1.  0.  0.]\n",
      " [ 0.  1. -1.  3. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "A_augmented = np.array([[1,1,0,2,-1,0],[1,0,1,-1,0,0],[3,1,2,0,-1,0]])\n",
    "A_augmented_reduced = lag.FullRowReduction(A_augmented)\n",
    "print(A_augmented_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b556191",
   "metadata": {},
   "source": [
    "There exist pivots in the first two columns only, so $x_3,x_4,$ and $x_5$ are free variables. If we parametrize them as $x_3 = r$, $x_4 = s$, and $x_5 = t$ then $x_1 = -r + s$ and $x_2 = r -3s + t$. Then we can write the components of a general solution vector $X$ in terms of these parameters.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X = \\left[ \\begin{array}{r} x_1 \\\\ x_ 2 \\\\ x_ 3 \\\\ x_4 \\\\ x_5 \\end{array}\\right] =  \n",
    "r\\left[ \\begin{array}{r} -1 \\\\ 1 \\\\  1 \\\\ 0 \\\\ 0 \\end{array}\\right] +\n",
    "s\\left[ \\begin{array}{r} 1 \\\\ -3 \\\\ 0 \\\\ 1 \\\\ 0 \\end{array}\\right] +\n",
    "t\\left[ \\begin{array}{r} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Therefore the follow set of vectors forms a basis for $\\mathcal{N}(A)$\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\left\\{ \\left[\\begin{array}{r} -1 \\\\ 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{array}\\right]\\hspace{0.2cm}, \\hspace{0.2cm} \\left[\\begin{array}{r} 1 \\\\ -3 \\\\ 0 \\\\ 1 \\\\ 0 \\end{array}\\right]\\hspace{0.2cm}, \\hspace{0.2cm} \\left[\\begin{array}{r} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{array}\\right] \\right\\}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Similarily, to find a basis for $\\mathcal{N}(A^T)$ we must find the solutions to $A^TX = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd0cec8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1. 0.]\n",
      " [0. 1. 2. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "A_transpose_augmented = np.array([[1,1,3,0],[1,0,1,0],[0,1,2,0],[2,-1,0,0],[-1,0,-1,0]])\n",
    "A_transpose_augmented_reduced = lag.FullRowReduction(A_transpose_augmented)\n",
    "print(A_transpose_augmented_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f7357a",
   "metadata": {},
   "source": [
    "There exists pivots in the first two columns only, so $x_3$ is a free variable. If we parametrize $x_3 = r$ then $x_1 = -r$ and $x_2 = -2r$. Then we can write the components of a general solution vector $X$ in terms of $r$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X = \\left[ \\begin{array}{r} x_1 \\\\ x_ 2 \\\\ x_ 3 \\end{array}\\right] =  \n",
    "r\\left[ \\begin{array}{r} -1 \\\\ -2 \\\\  1 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Therefore the following set forms a basis for $\\mathcal{N}(A^T)$\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\left\\{ \\left[\\begin{array}{r} -1 \\\\ -2 \\\\ 1 \\end{array}\\right] \\right\\}\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d67d684",
   "metadata": {},
   "source": [
    "$(b)$ Show that each of the basis vectors of $\\mathcal{R}(A)$ are orthogonal to all of the basis vectors of $\\mathcal{N}(A)$.\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "To show that each of the basis vectors of $\\mathcal{R}(A)$ are orthogonal to all of the basis vectors of $\\mathcal{N}(A)$, we must take all of their dot products and verify that the result is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a51020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 \n",
      "\n",
      "0.0 \n",
      "\n",
      "0.0 \n",
      "\n",
      "0.0 \n",
      "\n",
      "0.0 \n",
      "\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "R1 = np.array([[1],[1],[0],[2],[-1]])\n",
    "R2 = np.array([[1],[0],[1],[-1],[0]])\n",
    "N1 = np.array([[-1],[1],[1],[0],[0]])\n",
    "N2 = np.array([[1],[-3],[0],[1],[0]])\n",
    "N3 = np.array([[0],[1],[0],[0],[1]])\n",
    "print(lag.DotProduct(R1,N1),'\\n')\n",
    "print(lag.DotProduct(R1,N2),'\\n')\n",
    "print(lag.DotProduct(R1,N3),'\\n')\n",
    "print(lag.DotProduct(R2,N1),'\\n')\n",
    "print(lag.DotProduct(R2,N2),'\\n')\n",
    "print(lag.DotProduct(R2,N3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee7d0b2",
   "metadata": {},
   "source": [
    "$(c)$ Show that each of the basis vectors of $\\mathcal{C}(A)$ are orthogonal to all of the basis vectors of $\\mathcal{N}(A^T)$.\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "To show that each of the basis vectors of $\\mathcal{C}(A)$ are orthogonal to all of the basis vectors of $\\mathcal{N}(A^T)$, we must take all of their dot products and verify that the result is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1646713c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 \n",
      "\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "C1 = np.array([[1],[1],[3]])\n",
    "C2 = np.array([[1],[0],[1]])\n",
    "N = np.array([[-1],[-2],[1]])\n",
    "print(lag.DotProduct(C1,N),'\\n')\n",
    "print(lag.DotProduct(C2,N))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a83e70d",
   "metadata": {},
   "source": [
    "**Exercise 12:** The equation $x + 2y - 3z = 0$ defines a plane in $\\mathbb{R}^3$.\n",
    "\n",
    "\n",
    "$(a)$ Find a matrix that has this plane as its null space. Is the matrix unique?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae825a41",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Let $A$ and $B$ be the matrices defined below.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A = \\left[ \\begin{array}{r} 1 & 2 & -3 \\end{array}\\right] \\hspace{0.7cm} B = \\left[ \\begin{array}{r} x \\\\ y \\\\ z \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The null space of $A$ is the set of vectors $X$ such that $AX = 0$ but $AB = x + 2y - 3z = 0$ so any point on the given plane is also a solution to $AX = 0$ and is thus in the null space of $A$. $A$ is not the unique matrix with this feature, however, as any scalar multiple of $A$ will work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abc8403",
   "metadata": {},
   "source": [
    "$(b)$ Find a matrix that has this plane as its row space. Is the matrix unique?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308ed5a6",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "If we parametrize $y = r$ and $z = s$ then for any given point on the plane, $x = -2r + 3s$. Then we can write the components of a general vector  $X$  in the plane in terms of these parameters.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X = \n",
    "r\\left[ \\begin{array}{r} -2 \\\\ 1 \\\\ 0 \\end{array}\\right] + s\\left[ \\begin{array}{r} 3 \\\\ 0 \\\\  1 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "If we let $A$ be the matrix defined below then the span of the rows of $A$, or in other words the row space of $A$, will be precisely the points on the given plane. $A$ is not the unique matrix with this feature, however, as any other matrix that was reached by applying **matrix row operations** on $A$ will also work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c1b721",
   "metadata": {},
   "source": [
    "### Least Squares Solutions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4508afe6",
   "metadata": {},
   "source": [
    "**Exercise 1:** Verify that the following system is inconsistent, then find the least squares solution.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    x_2 + x_3 & = & 3 \\\\\n",
    "3x_1 - x_2 - 2x_3 & = & 2 \\\\\n",
    "x_1 - 2x_2 - x_3 & = & 1 \\\\\n",
    "4x_1 + 2x_2 + 4x_3 & = & 0\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df5415",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Let $A$ be the $4 \\times 3$ coefficient matrix, and let B be the vector of the right-hand sides of the equations. To verify that the system is indeed inconsistent, we can compute the RREF of the augmented matrix $[A|B].$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d470197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "A_augmented = np.array([[0,1,1,3],[3,-1,-2,2],[1,-2,-1,1],[4,2,4,0]])\n",
    "A_augmented_reduced = lag.FullRowReduction(A_augmented)\n",
    "print(A_augmented_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4f040",
   "metadata": {},
   "source": [
    "The pivot in the final column indicates that this system is inconsistent. To find the least squares solution, we will construct and solve the normal equations, $A^TAX = A^TB$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "249fa2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  3  9]\n",
      " [ 3 10 13]\n",
      " [ 9 13 22]] \n",
      "\n",
      "[[ 7]\n",
      " [-1]\n",
      " [-2]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0,1,1],[3,-1,-2],[1,-2,-1],[4,2,4]])\n",
    "B = np.array([[3],[2],[1],[0]])\n",
    "\n",
    "N_A = A.transpose()@A\n",
    "N_B = A.transpose()@B\n",
    "\n",
    "print(N_A,'\\n')\n",
    "print(N_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f997be4",
   "metadata": {},
   "source": [
    "The normal equations are a $3 \\times 3$ system, which can be solved using elimination.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "26x_1 + 3x_2 + 9x_3 & = & 7 \\\\\n",
    "3x_1 + 10x_2 + 13x_3 & = & -1\\\\\n",
    "9x_1 + 13x_2 + 22x_3 & = & -2\n",
    "\\end{eqnarray*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "811d1d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4       ]\n",
      " [ 0.47843137]\n",
      " [-0.5372549 ]] \n",
      "\n",
      "Magnitude of minimum error is: 3.256366313642777\n"
     ]
    }
   ],
   "source": [
    "X_hat = lag.SolveSystem(N_A,N_B)\n",
    "print(X_hat,'\\n')\n",
    "E = A@X_hat - B\n",
    "print(\"Magnitude of minimum error is:\",lag.Magnitude(E))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af988b8",
   "metadata": {},
   "source": [
    "**Exercise 2:** Another way to compute $\\hat{B}$ is to find an orthogonal basis for $\\mathcal{C}(A)$, find the projection of $B$ in the direction of each of those basis elements, and then add up these projections.  Demonstrate this calculation using $A$ and $B$ from **Example 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ad3a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e12d7e1",
   "metadata": {},
   "source": [
    "**Exercise 3:** Explain why an inconsistent system, $AX=B$, does not have a unique least squares solution if the columns of $A$ are linearly dependent.\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "If the columns of $A$ are linearly dependent, then there exists some nonzero $x$ such that $Ax = 0$. For this same $x$, we have that $A^TAx = A^T0 = 0$ and so the columns of $A^TA$ must also be linearly dependent. But recall that a general system $CX = D$ has a unique solution if and only if the columns of $C$ are linearly independent, and thus $A^TAX = A^TB$ does not have a unique solution. This means that $AX=B$ does not have a unique least squares solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3d62bb",
   "metadata": {},
   "source": [
    "**Exercise 4:** Demonstrate that the following inconsistent system does not have a unique least squares solution.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    x_2 - x_3 & = & 3 \\\\\n",
    "3x_1 - x_2 + 4x_3 & = & 2 \\\\\n",
    "x_1 - 2x_2 + 3x_3 & = & 1 \\\\\n",
    "4x_1 + 2x_2 + 2x_3 & = & 0\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "This can be seen quite easily if we utilize **normal equations**. Let $A$ be the $4 \\times 3$ coefficient matrix, and let B be the vector of the right-hand sides of the equations. Now we construct and solve the normal equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3622d799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.          1.          0.29083665]\n",
      " [ 0.          1.         -1.         -0.187251  ]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0,1,-1],[3,-1,4],[1,-2,3],[4,2,2]])\n",
    "B = np.array([[3],[2],[1],[0]])\n",
    "N_A = A.transpose()@A\n",
    "N_B = A.transpose()@B\n",
    "C = np.hstack([N_A,N_B])\n",
    "C_reduced = lag.FullRowReduction(C)\n",
    "print(C_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c742978a",
   "metadata": {},
   "source": [
    "This system has no pivots in the last column so it is consistent, but it also has no pivot in the third column which means there is a free variable, and thus an infinite number of solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b990cae",
   "metadata": {},
   "source": [
    "**Exercise 5:** If the system $AX = B$ is inconsistent, find the least squares solution to it and determine whether or not the least squares solution is unique.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A = \\left[\\begin{array}{rr} 1 & 2 & 3 \\\\ 1 & 1 & 1 \\\\ 2 & 2 & 0 \\\\ 1 & 2 & 1 \\end{array}\\right]\n",
    "\\quad\\quad\n",
    "B = \\left[\\begin{array}{r} 1 \\\\1 \\\\ 1 \\\\ 1 \\end{array}\\right]  \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a359dbdb",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "First we check if the given system is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd97f740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reduced form of A_aug is: \n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the matrix A:\n",
    "\n",
    "A_aug = np.array([[1,2,3,1],[1,1,1,1],[2,2,0,1],[1,2,1,1]])\n",
    "A_aug_red = lag.FullRowReduction(A_aug)\n",
    "\n",
    "print(\"The reduced form of A_aug is: \\n\", A_aug_red, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5f5a72",
   "metadata": {},
   "source": [
    "The pivot in last column of the augmented matrix shows that the given system is inconsistent.  As there is a pivot in each column of the matrix $A$, we know that the columns are linearly independent and we should expect the least squares solution to be unique.  We find the least squares solution by using the normal equations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f723d836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      " [[0.42857143]\n",
      " [0.14285714]\n",
      " [0.14285714]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the matrix A and B:\n",
    "\n",
    "A = np.array([[1,2,3],[1,1,1],[2,2,0],[1,2,1]])\n",
    "B = np.array([[1],[1],[1],[1]])\n",
    "\n",
    "A_trans = np.transpose(A)\n",
    "C = A_trans@A\n",
    "D = A_trans@B\n",
    "\n",
    "X = lag.SolveSystem(C, D)\n",
    "\n",
    "print(\"X: \\n\", X, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8895d3",
   "metadata": {},
   "source": [
    "**Exercise 6:** Find the equation of the line that best fits through the three given points:  $(0,2), (0,3)$ and $(1,4)$ in the sense of least squares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337c5729",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "The general equation of a line is $y = mx + c$.  Plugging in the given values of $x$ and $y$, we get three equations in $m$ and $c$.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    (0)m + c & = & 2 \\\\\n",
    "(0)m  + c & = & 3 \\\\\n",
    "(1)m + c & = & 4 \\\\\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "The system of equations has no solution because $c = 2$ from the first equation and $c = 3$ from the second equation.\n",
    "\n",
    "The corresponding matrix equation is:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "AX = \\left[\\begin{array}{rr} 0 & 1  \\\\ 0 & 1 \\\\ 1 & 1 \\end{array}\\right]\\left[\\begin{array}{r} m \\\\c  \\end{array}\\right] = \\left[\\begin{array}{r} 2 \\\\3 \\\\ 4  \\end{array}\\right]   = B \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Now, we can find the least squares solution using the normal equations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdfbc92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      " [[1.5]\n",
      " [2.5]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the matrix A:\n",
    "A = np.array([[0,1],[0,1],[1,1]])\n",
    "B = np.array([[2],[3],[4]])\n",
    "\n",
    "A_trans = np.transpose(A)\n",
    "\n",
    "C = A_trans@A\n",
    "D = A_trans@B\n",
    "\n",
    "X = lag.SolveSystem(C, D)\n",
    "\n",
    "print(\"X: \\n\", X , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cd764a",
   "metadata": {},
   "source": [
    "The equation of the line that best fits through the given points is $y = 1.5x + 2.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f4d17",
   "metadata": {},
   "source": [
    "**Exercise 7:** Find the equation of the parabola that best fits through the given points: $(-1,2), (1,0), (3,1)$ and $(4,2)$ in the sense of least squares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9528dd10",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "The general equation of a parabola is $y = ax^2 + bx + c$.  Plugging in the given values of $x$ and $y$, we get equations in $a$, $b$, and $c$:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    a \\,\\,\\,- b\\,\\,\\,  + c & = & 2 \\\\\n",
    "a \\,\\,\\,+ b\\,\\,\\, + c & = & 0 \\\\\n",
    "9a + 3b + c & = & 1 \\\\\n",
    "16a + 4b + c & = & 2 \\\\\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "\n",
    "The corresponding matrix equation is:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "AX = \n",
    "\\left[\\begin{array}{rr} 1 & -1 & 1  \\\\ 1 & 1 & 1 \\\\ 9 & 3 & 1 \\\\ 16 & 4 & 1 \\end{array}\\right]\\left[\\begin{array}{r} a \\\\b \\\\ c \\end{array}\\right] = \n",
    "\\left[\\begin{array}{r} 2 \\\\0 \\\\ 1 \\\\ 2  \\end{array}\\right]   = B \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "We first determine if the system is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb14fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reduced form of A_aug is: \n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "A_aug = np.array([[1, -1, 1, 2],[1,1,1,0],[9,3,1,1],[16,4, 1, 2]])\n",
    "A_aug_red = lag.FullRowReduction(A_aug)\n",
    "\n",
    "print(\"The reduced form of A_aug is: \\n\", A_aug_red, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7356bf",
   "metadata": {},
   "source": [
    "The pivot in the last column of the augmented matrix shows that the given system is inconsistent. We next find the least squares solution. Since there is a pivot in each column of the cofficient matrix $A$, the columns of $A$ are linearly independent and there is a unique least squares solution to this system.\n",
    "\n",
    "We find the solution using the normal equations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9763337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      " [[ 0.31532663]\n",
      " [-0.91834171]\n",
      " [ 0.72864322]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the matrices A and B:\n",
    "\n",
    "A = np.array([[1,-1,1],[1,1,1],[9,3,1],[16,4,1]])\n",
    "B = np.array([[2],[0],[1],[2]])\n",
    "\n",
    "A_trans = np.transpose(A)\n",
    "\n",
    "C = A_trans@A\n",
    "D = A_trans@B\n",
    "\n",
    "X = lag.SolveSystem(C,D)\n",
    "\n",
    "print(\"X: \\n\", X, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee06861f",
   "metadata": {},
   "source": [
    "We have got the values of $a$, $b$ and $c$ from the computations done in the above code cell. Therefore, the equation of the parabola that best fits through the given points is $y  = 0.315x^2  - 0.918x + 0.72864$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1532722e",
   "metadata": {},
   "source": [
    "**Exercise 8:** Find the least squares solution for the given system $AX = B$ without using the normal equations. Instead, find the orthogonal projection of $B$ onto $C(A)$ to find the least squares solution. Is the solution unique?\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A = \\left[\\begin{array}{rr} 1 & 2 & 2 \\\\ 2 & 1 & 4 \\\\ 1 & 2 & 2 \\end{array}\\right]\n",
    "\\quad\\quad\n",
    "B= \\left[\\begin{array}{r} 1 \\\\1 \\\\ 2 \\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709fdd99",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Let us first look at the columns of the matrix $A$. If the columns of $A$ are linearly independent, then there will be a unique solution for the system. If the columns are linearly dependent, there are infinitely many least square solutions to the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17d56a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_red: \n",
      " [[1. 0. 2.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the matrix A:\n",
    "\n",
    "A = np.array([[1,2,2],[2,1,4],[1,2,2]])\n",
    "A_red = lag.FullRowReduction(A)\n",
    "\n",
    "print(\"A_red: \\n\", A_red, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834877f2",
   "metadata": {},
   "source": [
    "Since there is no pivot in the third column since the third column we should expect infintely many least square solutions for the given system.\n",
    "\n",
    "Since there are pivots in two columns of $A$, $dim(C(A) = 2$. The basis for $C(A)$ is $\\{C_1,C_2\\}$ where\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "C_1 = \\left[\\begin{array}{r} 1 \\\\ 2 \\\\ 1  \\end{array}\\right]  \\hspace{1cm}\n",
    "C_2 = \\left[\\begin{array}{r} 2 \\\\ 1 \\\\ 2  \\end{array}\\right]  \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "Let the orthonormal basis for $C(A)$ is: $\\{U_1,U_2\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10dded48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U_1: \n",
      " [[0.40824829]\n",
      " [0.81649658]\n",
      " [0.40824829]] \n",
      "\n",
      "U_2: \n",
      " [[ 0.57735027]\n",
      " [-0.57735027]\n",
      " [ 0.57735027]] \n",
      "\n",
      "B_cap: \n",
      " [[ 0.31532663]\n",
      " [-0.91834171]\n",
      " [ 0.72864322]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the vectors B, C_1, C_2:\n",
    "\n",
    "B = np.array([[1],[1],[2]])\n",
    "C_1 = np.array([[1],[2],[1]])\n",
    "C_2 = np.array([[2],[1],[2]])\n",
    "\n",
    "\n",
    "## V_1, V_2 are orthogonal basis vectors for C(A):\n",
    "\n",
    "\n",
    "V_1 = C_1\n",
    "V_2 = C_2 - (lag.DotProduct(V_1, C_2)/lag.DotProduct(V_1,V_1))*V_1\n",
    "\n",
    "# Building U_1,U_2 by scaling V_1, V_2:\n",
    "\n",
    "U_1 = V_1/math.sqrt(lag.DotProduct(V_1,V_1))\n",
    "U_2 = V_2/math.sqrt(lag.DotProduct(V_2, V_2))\n",
    "\n",
    "print(\"U_1: \\n\", U_1, '\\n')\n",
    "print(\"U_2: \\n\", U_2, '\\n')\n",
    "\n",
    "## Finding the projection of B onto C(A):\n",
    "\n",
    "B_cap = lag.DotProduct(B, U_1)*U_1 + lag.DotProduct(B, U_2)*U_2\n",
    "\n",
    "print(\"B_cap: \\n\", X,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06254981",
   "metadata": {},
   "source": [
    "In the above code cell, $\\hat{B}$  represents the orthogonal projection of $B$ onto $C(A)$.\n",
    "\n",
    "Now, we need to solve the system:\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\left[\\begin{array}{rrr} 1 & 2 & 2 \\\\ 2 & 1 & 4 \\\\ 1 & 2 & 2  \\end{array}\\right] \\hat{X} = \\left[\\begin{array}{r} 1.5 \\\\1 \\\\ 1.5 \\end{array}\\right]  \n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a547e7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_aug_red: \n",
      " [[1.         0.         2.         0.16666667]\n",
      " [0.         1.         0.         0.66666667]\n",
      " [0.         0.         0.         0.        ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "A_aug = np.array([[1,2,2,1.5],[2,1,4,1],[1,2,2,1.5]])\n",
    "A_aug_red = lag.FullRowReduction(A_aug)\n",
    "\n",
    "print(\"A_aug_red: \\n\", A_aug_red, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9155d0c",
   "metadata": {},
   "source": [
    "Let\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{X} = \\left[\\begin{array}{r} a \\\\b \\\\ c\\end{array}\\right]  \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "We can see that $c$ is a free variable. So, let $c=t$ where $t$ is a scalar. Then, $b = 0.67$, $a = 0.167 - 2t$.\n",
    "\n",
    "\n",
    "So, \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{X} = \\left[\\begin{array}{r} 0.167-2t \\\\ 0.67 \\\\ t\\end{array}\\right]    \n",
    "= \\left[\\begin{array}{r} 0.167 \\\\ 0.67 \\\\ 0\\end{array}\\right]  +t\\left[\\begin{array}{r} -2 \\\\ 0 \\\\ 1\\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Hence, we can conclude that there are infintely many solutions for the system $ A\\hat{X} = \\hat{B}$. One possible solution is:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{X} = \\left[\\begin{array}{r} 0.167 \\\\ 0.67 \\\\ 0\\end{array}\\right]    \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "when $t=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ae62bb",
   "metadata": {},
   "source": [
    "**Exercise 9:** Can you use $QR$ factorization in **Exercise 7** to solve the normal equation ? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d350ee",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "No, we cannot use $QR$ factorization in **Exercise 7** to solve the normal equation because $QR$ factorization exists only if the columns of the matrix $A$ are linearly independent.  In **Exercise 7**, we saw that column three was a multiple of the first column.  Therefore, the columns of the matrix $A$ were linearly dependent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2044c4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
